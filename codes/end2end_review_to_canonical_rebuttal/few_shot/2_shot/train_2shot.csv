reviews	canonical_rebuttals
"The paper not only claims 'large scale representation learning' but also utilizing the described idea to use neural networks to ""directly, approximately solve non-convex NP-hard optimization problems that arise naturally in unsupervised learning problems."" Both claims are not really shown in the paper: (i) The experiments are not large scale and (ii)  it becomes not clear how any substantiate insight with respect to NP-hard problems can be gained here apart from the fact that it tackles a ML problem, which many seem to be computationally hard problems.' [SEP] 'rebuttal_mitigate-criticism"	This is, once again, motivated by making something work with modest amount of computation.
So at the end, I am a bit puzzled. I really like the idea, but I have the feeling that this technique should have been developed for more complicated setting. Or maybe it is actually not working on more difficult combinatorial problem (and this is hidden in the paper).' [SEP] 'rebuttal_mitigate-criticism	This is, once again, motivated by making something work with modest amount of computation.
In this simple model, can we not calculate the mutual information directly (i.e., without the bottleneck)?' [SEP] 'rebuttal_reject-request	Footnote 2 warned the reader about this, as we know it is unusual.
"- My main concern is reproducibility: the authors employ a number of large architectures, complex loss functions, and regularizers / ""additional improvements"".' [SEP] 'rebuttal_reject-request"	Footnote 2 warned the reader about this, as we know it is unusual.
This was a fun, albeit incremental paper.' [SEP] 'rebuttal_concede-criticism	[A1] As the reviewer pointed out, we adopted the partial components with the previously proposed techniques or methodologies.
Overall, this paper is good, but is not novel or important enough for acceptance.' [SEP] 'rebuttal_concede-criticism	[A1] As the reviewer pointed out, we adopted the partial components with the previously proposed techniques or methodologies.
The empirical evaluation is quite weak- one sparsity setting, two baselines, one dataset' [SEP] 'rebuttal_done	"You can check the details in the appendix of the paper, the paragraph of ""Applying Our Proposed Metric on FFHQ""."
Regarding contrastive explanations, experiments on datasets where distractor classes (y_probe) are present in addition to the class interest (y_true) seem important -- PASCAL VOC, COCO, etc.' [SEP] 'rebuttal_done	"You can check the details in the appendix of the paper, the paragraph of ""Applying Our Proposed Metric on FFHQ""."
While the comparison with HSIC is a helpful one, it is also required to compare with the competing method closest to yours, i.e.' [SEP] 'rebuttal_done	Complementary experiments have thus been performed, and tables 1, 2 updated.
The authors acknowledge this connection, but I think they should begin by introducing CE and then explain how Cakewalk generalizes it.' [SEP] 'rebuttal_done	Complementary experiments have thus been performed, and tables 1, 2 updated.
I do not think this work is ready for publication.' [SEP] 'rebuttal_structuring	Q1: “There are a few grammatical/spelling errors that need ironing out.”
Based on the summary, cons, and pros, the current rating I am giving now is weak reject. I would like to discuss the final rating with other reviewers, ACs.' [SEP] 'rebuttal_structuring	Q1: “There are a few grammatical/spelling errors that need ironing out.”
The theoretical contribution is very limited.' [SEP] 'rebuttal_mitigate-criticism	We followed their guidelines and included the results to provide convincing evidence that, in this extreme scenario, our model can perform better (even without the use of rationales).
The combination of ideas is ok, however, it is unclear how novel or how good is the proposed MF training of the RBMs.' [SEP] 'rebuttal_mitigate-criticism	We followed their guidelines and included the results to provide convincing evidence that, in this extreme scenario, our model can perform better (even without the use of rationales).
The main issue of this paper is the fair comparisons with other works.' [SEP] 'rebuttal_reject-criticism	Therefore, a comparison with [1, 2, 3, 4] is not straightforward as our goal is different.
1) Although the ensemble idea is new, the idea of selective self-training is not novel in self-training or co-training of SSL as in the following survey.' [SEP] 'rebuttal_reject-criticism	Therefore, a comparison with [1, 2, 3, 4] is not straightforward as our goal is different.
Thus we may only apply the proposed model on a few tasks with exactly known F.' [SEP] 'rebuttal_by-cr	We will publish the code to compute conductance after the blind-review phase.
- (W6) Motivation for CFS: I still don't fully understand the need to understand the density of the representation (especially in the manner proposed in the paper). Why is this an important problem? Perhaps expanding on this would be helpful' [SEP] 'rebuttal_by-cr	We will publish the code to compute conductance after the blind-review phase.
3. [Presentation.] The presentation is undesirable. It may make the readers hard to follow the paper.' [SEP] 'rebuttal_answer	Q2: The main contribution is listed as follows:
This issues makes reviewing this paper very difficult.' [SEP] 'rebuttal_answer	Q2: The main contribution is listed as follows:
3. The architecture of the neural networks used for the Generator and Discriminator is very non-standard, which' [SEP] 'rebuttal_other	This comment was also made in the official blind review #2.
"Furthermore PTB is not a ""challenging"" LM benchmark.' [SEP] 'rebuttal_other"	This comment was also made in the official blind review #2.
The paper misses the key baseline in Bayesian optimisation using tree structure [1] which can perform the prediction under the tree-structure dependencies.' [SEP] 'rebuttal_concede-criticism	We missed this previous work.
This is a thriving area that requires a careful literature review.' [SEP] 'rebuttal_concede-criticism	We missed this previous work.
One drawback is that it is highly specific to language models.' [SEP] 'rebuttal_reject-criticism	All of these insights are supported by a fair and unbiased rigorous experimental process.
As pointed out in the weakness section, many design choices are not well motivated, and the effects of those designs are not well studied.' [SEP] 'rebuttal_reject-criticism	All of these insights are supported by a fair and unbiased rigorous experimental process.
Due to the different objects used in the different datasets, some of the experiments have a smaller set of words.' [SEP] 'rebuttal_done	First, we agree that assumption (H2) is restrictive and have added some insights/results relaxing it in Section 3.4 in the latest version of the paper.
- Some of the datasets the authors currently test on are quite toy, especially for the image-based MNIST and SVHN datasets.' [SEP] 'rebuttal_done	First, we agree that assumption (H2) is restrictive and have added some insights/results relaxing it in Section 3.4 in the latest version of the paper.
Second, and more importantly, the experiments need to be re-done to better measure the practical impact of the techniques.' [SEP] 'rebuttal_future	However, as the main goal of this paper is to introduce and analyze the model, we defer more application-focused analysis to future work.
The MNIST is a relatively simple experiment, and I would like to see how the method works in more challenging problems.' [SEP] 'rebuttal_future	However, as the main goal of this paper is to introduce and analyze the model, we defer more application-focused analysis to future work.
I do not see these experimental settings mentioned anywhere in the paper, and this is very concerning.' [SEP] 'rebuttal_structuring	Please refer to Table 3 and Appendix C.4 for updated comparison results.
These synthetic setting can be used for sanity check, but cannot be the main part of the experiments.' [SEP] 'rebuttal_structuring	Please refer to Table 3 and Appendix C.4 for updated comparison results.
However, the method they propose offers very little that is new when compared to e.g. Vaswani (https://arxiv.org/pdf/1706.03762.pdf, section 3.5) (the authors acknowledge this work several times).' [SEP] 'rebuttal_by-cr	We will definitely cite them in the paper and include a discussion in related work on how our scheme compares to that proposed in the two papers.
Unlike Arora's original work, the assumptions they make on their subject material are not supported enough, as in their lack of explanation of why linear addition of two word embeddings should be a bad idea for composition of the embedding vectors of two syntactically related words, and why the corrective term produced by their method makes this a good idea.' [SEP] 'rebuttal_by-cr	We will definitely cite them in the paper and include a discussion in related work on how our scheme compares to that proposed in the two papers.
- The premises of the analyses are not very convincing, limiting the significance of the paper.' [SEP] 'rebuttal_answer	Your interpretation of section 3 is exactly right.
While this assumption seems plausible,  no analysis has been done to verify it in a systematic way.' [SEP] 'rebuttal_answer	Your interpretation of section 3 is exactly right.
However, I think since this is few-shot learning with domain adaptation, there is no domain adaptation baselines being mentioned in comparison.' [SEP] 'rebuttal_by-cr	Having said that, we see how these areas might seem related, and we will revise the related work section to better emphasize the aforementioned differences.
Why not compare results to WGAN-GP in this case? Since the proposal of GANs, many papers addressed the mode collapse problem.' [SEP] 'rebuttal_by-cr	Having said that, we see how these areas might seem related, and we will revise the related work section to better emphasize the aforementioned differences.
While better than most of the baseline methods, the N^2 memory/computational complexity is not bad, but still too high to scale to very large graphs.' [SEP] 'rebuttal_future	Unfortunately we did not find enough time to implement and test this algorithm during the rebuttal stage, but we now mention this possibility as an interesting avenue for future work.
Therefore, I don’t find interesting to report how DDGC improve upon “no baseline”, because known methods do even better.' [SEP] 'rebuttal_future	Unfortunately we did not find enough time to implement and test this algorithm during the rebuttal stage, but we now mention this possibility as an interesting avenue for future work.
-I find the experimental studies a bit limited and I would expect larger studies which would have improve the interest of the paper.' [SEP] 'rebuttal_done	"Please refer to our updated ""Experiments"" section."
I also remain unconvinced by the response to my issue with the claim “Our experiments show that our networks can remember a large number of images and distinguish them from unseen images”, where the negative images are also seen by the memorization model, so they are not unseen.' [SEP] 'rebuttal_done	"Please refer to our updated ""Experiments"" section."
- (W6) Motivation for CFS: I still don't fully understand the need to understand the density of the representation (especially in the manner proposed in the paper). Why is this an important problem? Perhaps expanding on this would be helpful' [SEP] 'rebuttal_structuring	[Q] Limited amount of new insight.
- limited amount of new insight, which is limiting as new and better understanding of GANs and practical guidelines are arguably the main contribution of a work of this type' [SEP] 'rebuttal_structuring	[Q] Limited amount of new insight.
However, the explanation of the strategy wasn’t very clear for me, and the authors didn’t frame it as a major contribution.' [SEP] 'rebuttal_by-cr	In the next version of the manuscript (both in response to your review and that of referee 1) we will add a more intuitive discussion of these results which we agree are somewhat technical.
- The network architecture is never described, especially the transition from Conv to Dense and the layer sizes, making the work hard to reproduce.' [SEP] 'rebuttal_by-cr	In the next version of the manuscript (both in response to your review and that of referee 1) we will add a more intuitive discussion of these results which we agree are somewhat technical.
PS: After discussion, I think the motivation of the method is not clear to understand why the proposed method works.' [SEP] 'rebuttal_refute-question	*Please also see reply to reviewer #2 on a similar question of evaluating against other methods*
- Sec 3.3 the argmin is a set, then it is LMO $\in$ argmin.' [SEP] 'rebuttal_refute-question	*Please also see reply to reviewer #2 on a similar question of evaluating against other methods*
However, the results are a bit misleading in their reporting of the std error.' [SEP] 'rebuttal_structuring	Q: It is hard to say whether the results are applicable in practice; need updates to baselines and comparison with learning rate schedules.
But the paper only provides empirical results on sentimental analysis and digit recognition.' [SEP] 'rebuttal_structuring	Q: It is hard to say whether the results are applicable in practice; need updates to baselines and comparison with learning rate schedules.
As a minor note, were different feature extractors compared?' [SEP] 'rebuttal_by-cr	We have also updated the paper to highlight that our proposed proxy is to be understood as an initial, simple, working instance, with a lot of remaining future work that could extend and refine it.
The KL divergence regularization introduces extra randomness to the auxiliary labels and thus mitigates the problem, but it hardly provides any useful information except randomness.' [SEP] 'rebuttal_by-cr	We have also updated the paper to highlight that our proposed proxy is to be understood as an initial, simple, working instance, with a lot of remaining future work that could extend and refine it.
Third, it is rather surprising that the authors didn't mention anything about the traditional causal discovery methods based on conditional independence relations in the data, known as constraint-based methods, such as the PC algorithm (Spirtes et al., 1993), IC algorithm (Pearl, 2000), and FCI (Spirtes et al., 1993).' [SEP] 'rebuttal_concede-criticism	We agree much detail on embeddings can be condensed or moved to Appendix.
Similarly, I'd have expected baselines that included those models in the evaluation section showing the differences in performance between the newly proposed Transformer model for trees and previously used methods.' [SEP] 'rebuttal_concede-criticism	We agree much detail on embeddings can be condensed or moved to Appendix.
2. during sampling, either training or testing, how do authors handle temporal overlap or make it overlap?' [SEP] 'rebuttal_structuring	It would be nice if the authors pointed to a git repository with their code an experiments.
Without an empirical example in a realistic setting, it is hard to judge whether the benefits of introducing an ME bias for better classification of new inputs belonging to new classes can outweigh the negatives via a potential increase in misclassification of those belonging to old classes.' [SEP] 'rebuttal_structuring	It would be nice if the authors pointed to a git repository with their code an experiments.
It is also not clear to me why these problems are important.' [SEP] 'rebuttal_reject-criticism	We are of course willing to further specify any details that the referee misses in the current paper. We would therefore like to kindly invite the referee to be specific about the details that he/she would like to be added to the manuscript.
2. The paper never clearly demonstrates the problem they are trying to solve (nor well differentiates it from the compressed sensing problem  or sample selection problem)' [SEP] 'rebuttal_reject-criticism	We are of course willing to further specify any details that the referee misses in the current paper. We would therefore like to kindly invite the referee to be specific about the details that he/she would like to be added to the manuscript.
* The differences between UNIT (GAN; C-po) and UNIT (MMD; C-po) in Table 1 seem very small and I'm not convinced that they are significant. Why does the MMD version constitute an improvement? Or is it simply more stable to train?' [SEP] 'rebuttal_answer	We discuss this point at the bottom of page 4 after equation 6 and will further clarify.
The samples from MNIST in Figure 3 are indeed very blurry, supporting this.' [SEP] 'rebuttal_answer	We discuss this point at the bottom of page 4 after equation 6 and will further clarify.
2. How is the performance of a simpler baseline such as combining a subset of new domain as training set to train MAML or PN (probably in 5-shot, 5-class case)?' [SEP] 'rebuttal_structuring	Missing experiments to validate nature of bounds.
"4. Missing experiments to validate nature of bounds: Bartlett et al. [3] performed extensive experiments to exhibit the correct scaling of the generalization bounds with the ""model complexity"" introduced upto numerical constants.' [SEP] 'rebuttal_structuring"	Missing experiments to validate nature of bounds.
As a final point; the hyper parameters that were tuned for the MNF, noisy K-FAC and KFLA baselines are not on common ground.' [SEP] 'rebuttal_done	We revised the notations in the paper to make formulation clearer.
Third, it is rather surprising that the authors didn't mention anything about the traditional causal discovery methods based on conditional independence relations in the data, known as constraint-based methods, such as the PC algorithm (Spirtes et al., 1993), IC algorithm (Pearl, 2000), and FCI (Spirtes et al., 1993).' [SEP] 'rebuttal_done	We revised the notations in the paper to make formulation clearer.
1 The implementation steps of the proposed method (MoVE) are not clear.' [SEP] 'rebuttal_done	As suggested, we have utilized the appendices to give detailed information about the experimental setup.
The reasons for the use of the energy-based formulation are not clear to me.' [SEP] 'rebuttal_done	As suggested, we have utilized the appendices to give detailed information about the experimental setup.
* first paragraph page 2: some references to causality literature and definition of spuriousness as common cause' [SEP] 'rebuttal_answer	It would be difficult fit a detailed convergence analysis in our paper given the limited space provided.
little improvements over the baselines or even significantly worse. More importantly,' [SEP] 'rebuttal_answer	It would be difficult fit a detailed convergence analysis in our paper given the limited space provided.
It is not clear how the compression ratio in table 1 is obtained.' [SEP] 'rebuttal_done	We have modified parts of our paper to reflect these arguments better.
* minor: in figure 8 in the appendix, the results after 100 iterations is, as far as I understand, over a single replication, so is not particularly reliable (and will always be 100% of a single optimizer)' [SEP] 'rebuttal_done	We have modified parts of our paper to reflect these arguments better.
- for the experiment with Imagenet images, it is not very clear how many pictures are used. Is this number 2500?' [SEP] 'rebuttal_by-cr	We’ll include more details about hyperparameters and hyperparameter selection in any future revision.
However it's not clear how is this range used in practice ? Do you sample uniformly $\alpha$ in this range to train the linear interpolation ?' [SEP] 'rebuttal_by-cr	We’ll include more details about hyperparameters and hyperparameter selection in any future revision.
If this is a method for image recognition, it would be better to present results for a more substantial image recognition problem than MNIST and CIFAR-10.' [SEP] 'rebuttal_contradict-assertion	Please check the degraded images in Table 3.
I cannot understand from that part whether T(v_a, v_b,.) addition to v_a+v_b gives any improvement or not.' [SEP] 'rebuttal_contradict-assertion	Please check the degraded images in Table 3.
The clarity of this paper needs to be strengthened.' [SEP] 'rebuttal_reject-criticism	We invite the referee to be specific about the sections of the original manuscript that need more clarification, allowing us to revise these sections.
I think the paper could benefit from having this in the earlier sections.' [SEP] 'rebuttal_reject-criticism	We invite the referee to be specific about the sections of the original manuscript that need more clarification, allowing us to revise these sections.
Because of this concern, I believe the results in the paper can only really characterize the learning close to convergence, since the network is already able to provide correct classification.' [SEP] 'rebuttal_answer	We based our title on that paper since it extends some of its results to nonlinear neural networks.
While the authors do report some interesting results, they do a poor job of motivating the proposed extensions.' [SEP] 'rebuttal_answer	We based our title on that paper since it extends some of its results to nonlinear neural networks.
"-4 Talking about ""agents"" and ""Multi-Agent"" is a somewhat confusing given the slightly different use of the same term in the reinforcement literature. Why not just ""mapping"" or ""network""?' [SEP] 'rebuttal_done"	In the latest revision, we have 5 baselines from previous research and modern variants, which further showcases the significance of our work.
It is not well explained in the paper how this proxy correlates with the Learning progress criteria.' [SEP] 'rebuttal_done	In the latest revision, we have 5 baselines from previous research and modern variants, which further showcases the significance of our work.
A quick glance at Table 1 suggests that the bounds obtained through Theorem 3 are exponential in t and are mostly vacuous.' [SEP] 'rebuttal_done	-Thanks! This was indeed an error, which we’ve corrected in the updated draft.
- Why are there missing BLEU scores and the number of parameters in Table 1?' [SEP] 'rebuttal_done	-Thanks! This was indeed an error, which we’ve corrected in the updated draft.
Cons: While doing this leads to better convergence, each update is still very expensive compared to standard SGD, and for instance on vision tasks the algorithm needs to run for almost double the time to get similar accuracies as an SGD, adam solver.' [SEP] 'rebuttal_structuring	Q4: the implementation details section is a bit too high-level and does not contain enough details to reimplement the Author's technique.
"As previously mentioned in public comments on this forum, some points in the paper are not very clear; specifically regarding the loss function, the definition of ""edge-to-edge"" convolutions and generally the architectural choice related to the conditional GAN discriminator.' [SEP] 'rebuttal_structuring"	Q4: the implementation details section is a bit too high-level and does not contain enough details to reimplement the Author's technique.
The difference with the other reference model (SVG) is less clear.' [SEP] 'rebuttal_done	We renamed all the models based on the original papers and their properties.
I agree that local SO(2) invariance is too limiting. But it is not true that rotating filters is not effective in planar/volumetric CNNs, as shown by many recent papers on equivariant networks.' [SEP] 'rebuttal_done	We renamed all the models based on the original papers and their properties.
It is difficult to know what the theory says about the empirical results, given the tweaks discussed in Sec 2.2, and so it is difficult to know what is the benefit of the method versus the tweaks.' [SEP] 'rebuttal_concede-criticism	We focus on simpler domains to provide proof-of-concept results as the first step on this direction.
My assumption is the visual feature already contains the label information for image captioning.' [SEP] 'rebuttal_concede-criticism	We focus on simpler domains to provide proof-of-concept results as the first step on this direction.
- Lack of a strong explanation for the results or a solution to the problem' [SEP] 'rebuttal_done	>> We discussed the results of the experiments in pages 7-8. We will revise to make this discussion easier to find.
"* Some turns of phrase like ""recently gained a flourishing interest"", ""there is still a wide gap in quality of results"", ""which implies a variety of underlying factors"", ... are vague / do not make much sense and should probably be reformulated to enhance readability.' [SEP] 'rebuttal_done"	>> We discussed the results of the experiments in pages 7-8. We will revise to make this discussion easier to find.
Indeed, without referencing the original Pointer Network and (and especially the) Transformer papers, it would not be possible to understand this paper at all.' [SEP] 'rebuttal_done	1. We fully understand your concern and we have added detailed description in the supplemental materials to show the hyperparameters we use for baseline methods in the revision.
"For example, there are two ""the"" in the end of the third paragraph in Related Work.' [SEP] 'rebuttal_done"	1. We fully understand your concern and we have added detailed description in the supplemental materials to show the hyperparameters we use for baseline methods in the revision.
6. Validation data / test sets: Throughout this work, it is unclear what / how validation is performed.' [SEP] 'rebuttal_mitigate-criticism	So the measurement we proposed is a best-effort attempt that can hopefully give us some insights into this problem.
In particular, it is unclear what the assumption on the size of the unlabelled test set is.' [SEP] 'rebuttal_mitigate-criticism	So the measurement we proposed is a best-effort attempt that can hopefully give us some insights into this problem.
What instead is missing is an answer to the question: Is it worth using a neural graph? what are the advantages and disadvantages compared to previous approaches?' [SEP] 'rebuttal_summary	In the supplement we have included an analysis of the sensitivity of this algorithm to the threshold to discard training points.
As a final point; the hyper parameters that were tuned for the MNF, noisy K-FAC and KFLA baselines are not on common ground.' [SEP] 'rebuttal_summary	In the supplement we have included an analysis of the sensitivity of this algorithm to the threshold to discard training points.
- Some of the datasets the authors currently test on are quite toy, especially for the image-based MNIST and SVHN datasets.' [SEP] 'rebuttal_future	We agree - particularly for applications regarding the interpretability of deep representations as well as the manipulation of biases contained therein.
Q1: Has the authors tried more complicated datasets such as CIFAR-10 to evaluate the pGAN method? It would make the paper more convincing to add results on more complex datasets.' [SEP] 'rebuttal_future	We agree - particularly for applications regarding the interpretability of deep representations as well as the manipulation of biases contained therein.
-- The machine learned advice is assumed to be flawless at identifying the Heavy Hitters, authors might want to consider incorporating errors in the analysis.' [SEP] 'rebuttal_by-cr	Having said this, if by practice you meant that the neural network is accurately described by our theory during training then we do not expect this to be true. We are happy to emphasize this in the camera ready.
I would have liked to see a bit more analysis as to why some pre-training strategies work over others.' [SEP] 'rebuttal_by-cr	Having said this, if by practice you meant that the neural network is accurately described by our theory during training then we do not expect this to be true. We are happy to emphasize this in the camera ready.
-- Since CounMin is closely related to Bloom filters the idea of using machine learning to speed it up appears to be noticeably less novel given that for Bloom filters this has already been done by Mitzenmacher’18.' [SEP] 'rebuttal_concede-criticism	We agree that some of the observations in sections 2 and 3 have already been made in previous work, however there are also several important differences:
For example, Narayanaswamy et al. [1] also propose to utilize labels to VAE.' [SEP] 'rebuttal_concede-criticism	We agree that some of the observations in sections 2 and 3 have already been made in previous work, however there are also several important differences:
Regarding the experiments on adversarial examples, I am not convinced of their relevance at all.' [SEP] 'rebuttal_done	We have addressed your concern about the baseline models and learning rate schedules in our updated paper.
* The experiments do not demonstrate that the model learns a meaningful *conditional* distribution for the missing modalities, since the provided figures show just one sample per conditioning image.' [SEP] 'rebuttal_done	We have addressed your concern about the baseline models and learning rate schedules in our updated paper.
The experiments were only done on simple image datasets.' [SEP] 'rebuttal_answer	In responding to this comment and the comment of Reviewer #1, we perform one more experiment on CelebA to demonstrate that DSGAN can work well even for complicated images.
In the real world, one would not have access to OOD data during training, how is one to pick \lambda in such cases?' [SEP] 'rebuttal_answer	In responding to this comment and the comment of Reviewer #1, we perform one more experiment on CelebA to demonstrate that DSGAN can work well even for complicated images.
- Figures 1-4 are difficult to interpreted on a printed version.' [SEP] 'rebuttal_by-cr	We have fixed the other issues you raised in your other minor comments. If you have any further comments, please let us know.
4. Fig. 3 (right): It is not clear' [SEP] 'rebuttal_by-cr	We have fixed the other issues you raised in your other minor comments. If you have any further comments, please let us know.
Though, I still think the contribution is incremental, since back-propagating gradients through values and dynamics has been studied in prior works (albeit with less empirical successes compared to Dreamer).' [SEP] 'rebuttal_reject-criticism	We emphasize that our theoretical analysis leads to significant more concise convergence bounds than those in the above papers.
The proposed method PowerSGD is an extension of the method in Yuan et al. (extended to handle stochastic gradient and momentum).' [SEP] 'rebuttal_reject-criticism	We emphasize that our theoretical analysis leads to significant more concise convergence bounds than those in the above papers.
- It would be nice to have an experiment that varies the size of the external paired sentence-image dataset and tested the impact on performance.' [SEP] 'rebuttal_structuring	> The experimental results presented were all done on small synthetic datasets and it’s hard to evaluate whether the method is practically useful.
2. Were there experiments that applies your metric to the training datasets like CelebA and FFHQ? In theory your metric should show no gap between N_R_obs and N_R_ref measured on the training dataset since that's the sampled ground truth.' [SEP] 'rebuttal_structuring	> The experimental results presented were all done on small synthetic datasets and it’s hard to evaluate whether the method is practically useful.
However, this limits the novelty of the results relative to existing literature.' [SEP] 'rebuttal_accept-praise	A1: As for novelty, we first thank you for acknowledging that understanding GANs from the control theory perspective is promising and enjoyable to read.
As the authors admit, the main result is not especially surprising.' [SEP] 'rebuttal_accept-praise	A1: As for novelty, we first thank you for acknowledging that understanding GANs from the control theory perspective is promising and enjoyable to read.
Does the discriminator exclude the poisoning data according to certain rule?' [SEP] 'rebuttal_done	We haved add the above discussion to the latest version as Appendix A.9.
1. What are the key limitations of AutoLoss ? Did we observe some undesirable behavior of the learned optimization schedule, especially when transfer between different datasets or different models ?' [SEP] 'rebuttal_done	We haved add the above discussion to the latest version as Appendix A.9.
However, all experiments only show results in the MCAR setting, so the claim is not experimentally validated.' [SEP] 'rebuttal_answer	Nonetheless, it is relatively easy for us to update the results in the paper with these new hyperparameters.
4. [Experiments.] The author presented a multimodal representation learning framework for partially-observable multimodal data, while the experiments cannot corraborrate the claim.' [SEP] 'rebuttal_answer	Nonetheless, it is relatively easy for us to update the results in the paper with these new hyperparameters.
"The paper also lacks experimental results, and the main conclusion from these results seems to be ""MNIST is not suitable for benchmarking of adversarial attacks"".' [SEP] 'rebuttal_social"	Thank you for pointing out the accuracy of ResNet-20 (similar to Reviewer 1).
The proposed sampling distributions assumes independence between the random variables over which the authors optimize — I find it surprising that this leads to good empirical results' [SEP] 'rebuttal_social	Thank you for pointing out the accuracy of ResNet-20 (similar to Reviewer 1).
With lack of clear novel insights, or at least more systematic study on additional datasets of the 'winning' techniques and a sensitivity analysis, the paper does not give a valuable enough contribution to the field to merit publication.' [SEP] 'rebuttal_reject-criticism	On top of that, our experiments are reproducible (as already reported by other works), we shared the resulting code and the pre-trained models.
If the novelty is in applying to continual learning and new datasets, it is not clear that this is sufficient.' [SEP] 'rebuttal_reject-criticism	On top of that, our experiments are reproducible (as already reported by other works), we shared the resulting code and the pre-trained models.
On the other hand, the authors give no evidence, empirical or otherwise, that their method is useful on any downstream tasks.' [SEP] 'rebuttal_summary	Please note that the data described in Figure 6c has been updated from Figure 7, and our method shows better performance in new data compared to the data shown in the original manuscript.
This is ultimately due to the fact that the set of alt-az rotations is not the same as the set of points on the sphere, topologically speaking.' [SEP] 'rebuttal_summary	Please note that the data described in Figure 6c has been updated from Figure 7, and our method shows better performance in new data compared to the data shown in the original manuscript.
1) I wonder if the proposed method work for most GAN models, more experiments evaluated on more recent GAN-based  models should be added to verify the superiority claimed in this paper, e.g., TP-GAN [Huang et al., ICCV 2017], PIM [Zhao et al., CVPR 2018], DR-GAN [Tran et al., CVPR 2017], DA-GAN [Zhao et al., NIPS 2017], MH-Parser [Li et al., 2017], 3D-PIM [Zhao et al., IJCAI 2018], SimGAN [Shrivastava et al., CVPR 2016], AIM [Zhao et al., AAAI 2019].' [SEP] 'rebuttal_by-cr	Q1: We are evaluating the proposed metrics on more recent GAN-based models you suggested and will update the results once the results become available.
Some details are missing, which is hardly reproduced by the other researchers.' [SEP] 'rebuttal_by-cr	Q1: We are evaluating the proposed metrics on more recent GAN-based models you suggested and will update the results once the results become available.
So at the end, I am a bit puzzled. I really like the idea, but I have the feeling that this technique should have been developed for more complicated setting. Or maybe it is actually not working on more difficult combinatorial problem (and this is hidden in the paper).' [SEP] 'rebuttal_by-cr	The updated paper will change the emphasis, and clarify that a proper learning progress proxy remains future work.
The main problem is that directly predicting the context is intractable because of combinatorial explosion.' [SEP] 'rebuttal_by-cr	The updated paper will change the emphasis, and clarify that a proper learning progress proxy remains future work.
The experiments on SHREC17 show all three spherical methods under-performing other approaches.' [SEP] 'rebuttal_by-cr	4. We plan to add SGD to the experiments, but this may take a while to complete, especially for some of the experiments.
In the current experiments there is a comparison only with CO algorithm and SGDA.' [SEP] 'rebuttal_by-cr	4. We plan to add SGD to the experiments, but this may take a while to complete, especially for some of the experiments.
2. Is it reasonable to assume some constraints on how much data we can get from the blackbox generator?' [SEP] 'rebuttal_structuring	7. The evaluation on two datasets seems to be rather limited, additional comparisons should be included.
For example, the number of labeled examples in Table 1 is fairly large and inconsistent (4K, 1K, 10K for the 3 organic datasets).' [SEP] 'rebuttal_structuring	7. The evaluation on two datasets seems to be rather limited, additional comparisons should be included.
There should be sufficient details for a reader to implement this model, thought there are some minor details missing regarding the experimental setup, which will be addressed below.' [SEP] 'rebuttal_reject-criticism	We agree with the reviewer that such a comparison would be possible but the experiments, we believe, would not reflect the message of the paper.
The experimental results are not very convincing because many importance baselines are neglected.' [SEP] 'rebuttal_reject-criticism	We agree with the reviewer that such a comparison would be possible but the experiments, we believe, would not reflect the message of the paper.
"I would have been interested in ""false detection"" experiments: comparing estimator in a variety of problems where the mutual information is zero, but for different marginal distribution.' [SEP] 'rebuttal_by-cr"	Further, we will add the details of preliminary experiments using pseudo-count in the supplementary.
It would be nice to see a better case made for spherical convolutions within the experimental section.' [SEP] 'rebuttal_by-cr	Further, we will add the details of preliminary experiments using pseudo-count in the supplementary.
- for the experiment with Imagenet images, it is not very clear how many pictures are used. Is this number 2500?' [SEP] 'rebuttal_answer	A4: We note that we have mentioned our attack formulation and algorithm in Section 2.2;
3. Shouldn't random indexing produce non-uniform numbers of non-zero entries depending on alpha? Why did you have an exact number of non-zero entries, s, in the experiments?' [SEP] 'rebuttal_answer	A4: We note that we have mentioned our attack formulation and algorithm in Section 2.2;
- That learning simple functions and composing them to compute more complex functions would be more data efficient than directly learning the complex functions does not seem very surprising.' [SEP] 'rebuttal_concede-criticism	It appears that our choice of the title may have resulted in the reviewer qualifying our paper as a form of false advertising.
The main appeal is the idea of using T to model syntactic interactions, and the algorithm for learning T. Given that the main attraction of the paper is the potential for more performant word embeddings, I do not believe the work will have wide appeal to ICLR attendees, because no evidence is provided that the features from the learned tensor, say [a, b, T*a*b], are more useful in downstream applications than [a,b] (one experiment in sentiment analysis is tried in the supplementary material with no compelling difference shown).' [SEP] 'rebuttal_concede-criticism	It appears that our choice of the title may have resulted in the reviewer qualifying our paper as a form of false advertising.
Another somewhat jarring fact about the alt-az convolution is that it is not well defined on the south pole.' [SEP] 'rebuttal_done	5. We have added further empirical evidence to show that in the revision.
"4. I do not understand this: ""to fit well the method overfitting rate"" in Section 3.3.' [SEP] 'rebuttal_done"	5. We have added further empirical evidence to show that in the revision.
- Some assumptions are not explicitly stated.' [SEP] 'rebuttal_followup	Could you please elaborate on the comment ’the current design […] simply sums them up’?
It is not clear that the notion of similarity through classifier weights makes sense, but see below for clarification questions.' [SEP] 'rebuttal_followup	Could you please elaborate on the comment ’the current design […] simply sums them up’?
-3 For image-to-image translation experiments, no quantitative analysis whatsoever is offered so the reader can't really conclude anything about the effect of the proposed method in this domain.' [SEP] 'rebuttal_social	We appreciate such detailed and rigorous convergence analysis provided in [1] and [2].
That said, I would like to see more analysis on the behavior of the proposed method under various interesting cases not tested yet.' [SEP] 'rebuttal_social	We appreciate such detailed and rigorous convergence analysis provided in [1] and [2].
This baseline was also missing in image reconstruction.' [SEP] 'rebuttal_structuring	[R3: Weakness: It would be good to see some comparison to the state of the art ]
For e.g. the results on the oscillating behavior of Dirac-GAN are described in related works (e.g. Mescheder et al. 2018), and in practice, WGAN with no regularization is not used (as well as GAN with momentum, as normally beta1=0 in practice).' [SEP] 'rebuttal_structuring	[R3: Weakness: It would be good to see some comparison to the state of the art ]
*The experimental section is too limited.' [SEP] 'rebuttal_followup	"- Could you be more specific on what do you expect for ""larger studies"" and ""general study”?  This will be helpful for improving our work."
However, I am wondering whether this paper is perfectly suited to ICLR conference due to the lack of experiment, practical implication given by the theory, or theory in the non-convex setting (I know that the latter is a huge open question and I am not criticizing the absence of theory in the non-convex-concave setting).' [SEP] 'rebuttal_followup	"- Could you be more specific on what do you expect for ""larger studies"" and ""general study”?  This will be helpful for improving our work."
It is unclear, why one should use the proposed duality gap GAN.' [SEP] 'rebuttal_reject-criticism	We appreciate the concern in the updated comments, but would like to point out that the novelty in our work should be viewed from two angles: the need to study this problem (i.e., the problem setting), and the proposed solution.
- That learning simple functions and composing them to compute more complex functions would be more data efficient than directly learning the complex functions does not seem very surprising.' [SEP] 'rebuttal_reject-criticism	We appreciate the concern in the updated comments, but would like to point out that the novelty in our work should be viewed from two angles: the need to study this problem (i.e., the problem setting), and the proposed solution.
However, these were done using 1 dataset and also a simple feed-forward network (rather than LSTM).' [SEP] 'rebuttal_by-cr	We are training DeepCluster now on a significantly less busy image and will report results in the coming days.
Weaknesses: The dataset created here is entirely synthetic, and the paper only includes one single small real-world case; it seems like it would be easy to generate a larger and more varied real world dataset as well (possibly from the large literature of extant solved problems in workbooks).' [SEP] 'rebuttal_by-cr	We are training DeepCluster now on a significantly less busy image and will report results in the coming days.
- The use of RAM is a fairly serious limitation of your experimental setting in my view. You should include results also for the pixel space, even if negative.' [SEP] 'rebuttal_summary	Note the compression rates are the same as the data in Table 3 in the original manuscript.
The way the permutation, or the order of the data, accounts in the likelihood (2) does not make sense.' [SEP] 'rebuttal_summary	Note the compression rates are the same as the data in Table 3 in the original manuscript.
I believe that this paper is thus not in its final form and could be largely improved.' [SEP] 'rebuttal_followup	Could the reviewer indicate which sections are found to be imprecise and unpolished, and which parts of the manuscript need a better presentation?
Overall, I find the paper a promising contribution. But until the authors provide a more thorough experimental evaluation, I hesitate to recommend acceptance.' [SEP] 'rebuttal_followup	Could the reviewer indicate which sections are found to be imprecise and unpolished, and which parts of the manuscript need a better presentation?
Moreover, authors should conduct experiments on state-of-the-art benchmarks, including natural images.' [SEP] 'rebuttal_structuring	Q2: The authors are expected to make more comprehensive analysis with the state-of-the-art methods, and also analyze why some alternative methods outperforms the proposed methods in table I and table II.
However, the experiments are overall not very useful to the comprehension of the paper and not that illustrative.' [SEP] 'rebuttal_structuring	Q2: The authors are expected to make more comprehensive analysis with the state-of-the-art methods, and also analyze why some alternative methods outperforms the proposed methods in table I and table II.
"With this dataset, it's a bit of a stretch to say there was ""only a 1 point drop in BLEU score"". That's a significant drop, and in fact the DynamicConv paper goes to significant lengths to make a smaller 0.8 point improvement.' [SEP] 'rebuttal_done"	We will incorporate these results in the experiments section and post the updated manuscript shortly.
The results on real datasets are similar to the regular GCN.' [SEP] 'rebuttal_done	We will incorporate these results in the experiments section and post the updated manuscript shortly.
Because of this concern, I believe the results in the paper can only really characterize the learning close to convergence, since the network is already able to provide correct classification.' [SEP] 'rebuttal_structuring	3. Are the authors willing to release the code?
"3.	Are the authors willing to release the code? Overall the model looks complicated and the appendix is not sufficient to reproduce the results in the paper.' [SEP] 'rebuttal_structuring"	3. Are the authors willing to release the code?
Cons:  unclear transfer learning model, insufficient experiments.' [SEP] 'rebuttal_structuring	Remark 1. Expression and detail
However, the real-world experiments are not necessarily the easiest to read.' [SEP] 'rebuttal_structuring	Remark 1. Expression and detail
Weaknesses: The main weakness of the paper is that the performance gains are extremely low compared to the next contender; perhaps they are statistically significant (this cannot be determined), but it's unclear why we wouldn't use GBDT.' [SEP] 'rebuttal_reject-criticism	For these two reasons, we are running the requested experiments and we hope to be able to update Table 4 in the following days.
A. You demonstrate the results on CIFAR-10 for 10% error rates which corresponds to networks which are far from what is currently used in deep learning.' [SEP] 'rebuttal_reject-criticism	For these two reasons, we are running the requested experiments and we hope to be able to update Table 4 in the following days.
Given there is no theoretical justification for the approximation, I believe the paper claims more than what it delivers and should change the presentation, so as not to claim that it is measuring and capturing learning progress to learn faster.' [SEP] 'rebuttal_concede-criticism	We also appreciate the reviewer taking their time to draw our attention to how to better emphasize the novelty and simplicity of our work.
For example using LASSO / LARS like methods you can perhaps figure out a good reduced dimension set more efficiently.' [SEP] 'rebuttal_concede-criticism	We also appreciate the reviewer taking their time to draw our attention to how to better emphasize the novelty and simplicity of our work.
- It would be nice if more network architectures were analysed (such as VGG and DenseNets).' [SEP] 'rebuttal_done	In the updated draft of our paper, we have updated the rigor of the theory section: please see Section 5 and Appendix C for updated theory.
I would have liked to see a bit more analysis as to why some pre-training strategies work over others.' [SEP] 'rebuttal_done	In the updated draft of our paper, we have updated the rigor of the theory section: please see Section 5 and Appendix C for updated theory.
- Lambda sim and lambda s are used interchangeably. Please make it consistent.' [SEP] 'rebuttal_future	While we have provided some diagnostics statistics, understanding deeply why this method helps will fuel interesting future research.
2. While the primary motivation of the work is claimed to be 'mode collapse', it does not turn out from the submission what mode collapse is.' [SEP] 'rebuttal_future	While we have provided some diagnostics statistics, understanding deeply why this method helps will fuel interesting future research.
See http://www.stat.cmu.edu/~ryantibs/convexopt-S15/scribes/08-prox-grad-scribed.pdf for a reference.' [SEP] 'rebuttal_answer	See ensuing discussion in p.18 following equation 36.
For example, “Fuzzy Choquet Integration of Deep Convolutional Neural Networks for Remote Sensing” by Derek T. Anderson et al.' [SEP] 'rebuttal_answer	See ensuing discussion in p.18 following equation 36.
(3) A large body of graph neural network literature is omitted.' [SEP] 'rebuttal_done	5. Thank you for pointing out this related work. We refer to it in the updated version of the submission.
There are some well-cited works that the authors may have missed. These are ultimately different approaches, but perhaps the authors can obtain some inspiration from these:' [SEP] 'rebuttal_done	5. Thank you for pointing out this related work. We refer to it in the updated version of the submission.
I believe it will not be great, but I think for completeness, you should add such a baseline.' [SEP] 'rebuttal_summary	As the reviewer can observe the scale of the experimental evaluation is significantly different.
4. The scores achieved by the baseline are very far from state of the art, making the comparison mostly useless,' [SEP] 'rebuttal_summary	As the reviewer can observe the scale of the experimental evaluation is significantly different.
I highly encourage the authors to finetune the ImageNet pre-trained BagNet on PASCAL VOC and compare to the previous patch-based deep networks.' [SEP] 'rebuttal_done	"We provided a detailed explanation about the experimental setting and further experimental results of the state-of-the-art performance in our response to ""The Common concerns about experimental setting and results""."
- For the automatic evaluation measures there should be multiple references per SPARQL query since this is how BLEU et al are supposed to be used.' [SEP] 'rebuttal_done	"We provided a detailed explanation about the experimental setting and further experimental results of the state-of-the-art performance in our response to ""The Common concerns about experimental setting and results""."
The figures are almost useless, because the captions contain very little information.' [SEP] 'rebuttal_answer	[A] What we can do is to separate the top from the bottom figure into separate figures and provide more information in the captions.
Typo:. The “Inf” in Tabel 1' [SEP] 'rebuttal_answer	[A] What we can do is to separate the top from the bottom figure into separate figures and provide more information in the captions.
Some details are missing, which is hardly reproduced by the other researchers.' [SEP] 'rebuttal_done	In addition to implementation details, the appendix has a rather detailed table of the architecture parameters.
It would be helpful to have a brief paragraph describing this architecture, for readers not familiar with the referenced paper.' [SEP] 'rebuttal_done	In addition to implementation details, the appendix has a rather detailed table of the architecture parameters.
This paper looks very hastily put together, especially pages 7 and 8.' [SEP] 'rebuttal_structuring	"R: ""The paper can benefit from a proofreading."""
The primary difficulty in reviewing this paper is the poor presentation of the paper.' [SEP] 'rebuttal_structuring	"R: ""The paper can benefit from a proofreading."""
First, many details are missing, especially in the experiments, which makes the proposed method suspicious and non-convincing.' [SEP] 'rebuttal_answer	Thanks to the comment from the reviewer, we were able to rearrange the content and set training iteration by cross-validation.)
-The experimental section do not clarify the benefits of the proposed approach.' [SEP] 'rebuttal_answer	Thanks to the comment from the reviewer, we were able to rearrange the content and set training iteration by cross-validation.)
- The arguments for why the experimental evidence actually supports the existance of an approximate number system (ANS) could be made more clear.' [SEP] 'rebuttal_reject-request	We believe that we have already demonstrated a significant improvement over the prior state-of-the-art, and additional experiments could be prohibitively expensive.
-I find the experimental studies a bit limited and I would expect larger studies which would have improve the interest of the paper.' [SEP] 'rebuttal_reject-request	We believe that we have already demonstrated a significant improvement over the prior state-of-the-art, and additional experiments could be prohibitively expensive.
Although the idea seems to be interesting, the paper seems to be a bit incremental and is a simple application of existing GAN techniques.' [SEP] 'rebuttal_answer	After taking a close look, we make the following observations:
- The idea is a simple extension of existing work.' [SEP] 'rebuttal_answer	After taking a close look, we make the following observations:
However, as the authors acknowledge the overall simplicity of the tasks being evaluated with mostly marginal improvements makes the overall evaluation fall short.' [SEP] 'rebuttal_by-cr	3)For the experiment: we will spend some time to train GANs with more iteration and modify it.
However, the results are unconvincing: only the results for epsilon = 0.1 are shown, and even so the advantage is marginal.' [SEP] 'rebuttal_by-cr	3)For the experiment: we will spend some time to train GANs with more iteration and modify it.
3. Since there are many tasks and each task has a large-scale data, I'm afraid that the running time will explode. How to deal with this issue?' [SEP] 'rebuttal_structuring	We believe that this is the Reviewer 1's core question so would like to justify our results more in detail in this response and try to convince the Reviewer.
- The experiments show good results compared to existing algorithms, but not impressively so.' [SEP] 'rebuttal_structuring	We believe that this is the Reviewer 1's core question so would like to justify our results more in detail in this response and try to convince the Reviewer.
The experimental results are not very convincing because many importance baselines are neglected.' [SEP] 'rebuttal_done	We clarified this in Section 2.1 of the revised draft.
Without a proper comparison (formal and experimental) with these lines of work, the paper is incomplete.' [SEP] 'rebuttal_done	We clarified this in Section 2.1 of the revised draft.
2. Although the experiments are detailed and interesting they support poor theoretical developments and use a very classical benchmark' [SEP] 'rebuttal_structuring	"3. ""Given the existing body of literature, I found the technical novelty of this paper rather weak"""
If this all is indeed the case, it is not surprising that the numbers the authors get in the experiments are so similar to WAE-MMD, because CWAE would be exactly WAE-MMD with a specific choice of the kernel.' [SEP] 'rebuttal_structuring	"3. ""Given the existing body of literature, I found the technical novelty of this paper rather weak"""
My overall concern is that the experiment result doesn’t really fully support the claim in the two aspects: 1) the SASNet takes the enriched dataset as input to the neural net but it also uses the complex (validation set) to train the optimal parameters, so strictly it doesn’t really fit in the “transfer” learning scenario.' [SEP] 'rebuttal_answer	As mentioned in the shared response, we believe that the speed-quality tradeoff of K-matrices could be further improved with more extensively tuned and optimized implementations.
In terms of evaluation, the authors only presented a few qualitative results on simple datasets, which is not comprehensive and convincing.' [SEP] 'rebuttal_answer	As mentioned in the shared response, we believe that the speed-quality tradeoff of K-matrices could be further improved with more extensively tuned and optimized implementations.
Without an empirical example in a realistic setting, it is hard to judge whether the benefits of introducing an ME bias for better classification of new inputs belonging to new classes can outweigh the negatives via a potential increase in misclassification of those belonging to old classes.' [SEP] 'rebuttal_done	We have also provided more details about LOAN dataset and how we attack in Appendix A.1.
Given this, I wonder why all experiments are conducted on sets of two to five images, even for Kitti where standard evaluation protocols would demand predicting entire sequences.' [SEP] 'rebuttal_done	We have also provided more details about LOAN dataset and how we attack in Appendix A.1.
They start from Equation (4) which is incorrectly denoted as the log-marginal distribution while it is the same conditional distribution introduced in Equation (3) with the extra summation for all the available data points.' [SEP] 'rebuttal_done	We added a new Section 4 in the revised version of the paper discussing these differences.
However, I can not agree because you can simply generate poisoned data and train the neural networks on the poisoned data regardless of the underlying approach that is targeted in generating the poisoned data.' [SEP] 'rebuttal_done	We added a new Section 4 in the revised version of the paper discussing these differences.
- White-box attack experiments don’t really prove the strength of the method, even with imagenet experiments, as almost all attacks get 100% success rate making it hard to compare.' [SEP] 'rebuttal_answer	Moreover, we investigate the mixing distribution learned in Appendix G.
So overall I have the feeling that the authors have not succeeded to evaluate the model’s power with these two experiments and we cannot draw any strong conclusions regarding the benefit of the proposed mixing approach.' [SEP] 'rebuttal_answer	Moreover, we investigate the mixing distribution learned in Appendix G.
"For example, ""The old system of private arbitration courts is off the table"" from DE-EN 2016 Dev doesn't seem like it should benefit from this architecture.' [SEP] 'rebuttal_done"	We have solved this issue thanks to the comments of the anonymous reviewers by now displaying the most and least active atoms.
After reading, the reviewer cannot understand why the user should bother to use hyperbolic representations that are more complex to compute in GCNs, given that the experimental results are roughly the same.' [SEP] 'rebuttal_done	We have solved this issue thanks to the comments of the anonymous reviewers by now displaying the most and least active atoms.
This also becomes apparent in the experiments section, where rotational data augmentation is found to be necessary.' [SEP] 'rebuttal_done	In light of the reviews, in the revised version, we have expanded the appendix to give more details on the experimental protocol.
In the real world, one would not have access to OOD data during training, how is one to pick \lambda in such cases?' [SEP] 'rebuttal_done	In light of the reviews, in the revised version, we have expanded the appendix to give more details on the experimental protocol.
However, the un-standard design of the LSTM models makes it unclear whether the comparisons are solid enough.' [SEP] 'rebuttal_answer	We have cited this work in our related works section, and mentioned its impact.
While the authors are using an existing model, they shouldn't assume that the reader has read the paper describing that model.' [SEP] 'rebuttal_answer	We have cited this work in our related works section, and mentioned its impact.
Specifically, there is some confusion about estimation of w~, which seems based on frequency estimation from past SGD iterations (Eq 3).' [SEP] 'rebuttal_reject-criticism	As far as explaining the method of combination, and the associated mathematical properties, we have tried to do this in greater detail in section 3 (Approach).
4. Even when the authors formally introduce \sigma and \omega in 4.2, it is still not clear that why both of them are used for modelling the success probability.' [SEP] 'rebuttal_reject-criticism	As far as explaining the method of combination, and the associated mathematical properties, we have tried to do this in greater detail in section 3 (Approach).
2. I think that the claim that the use of neural networks with discrete inputs can approximately solve NP-hard optimization problems is an exciting one, which likely necessitates more experiments (or theoretical results), but as it stands I don't think it is a fundamentally different conclusion from the fact that this method provides a great scalable solution for the ordinal embedding problem.' [SEP] 'rebuttal_social	2. Thank you for your suggestion.
Since the LM-like approach is the main contribution, and the reported experiments do not show an advantage over GN-like approaches (already taken by previous work), this is my main reason for proposing rejection.' [SEP] 'rebuttal_social	2. Thank you for your suggestion.
- Judging from Table 1, the proposed method does not seem to provide a large contribution.' [SEP] 'rebuttal_structuring	“Judging from Table 1, the proposed method does not seem to provide a large contribution.
-  From the plots of learning curves in appendix, the proposed methods doesn’t seem to show a huge boost of performance comparing to the uniform bandit. Could you show aggregated comparison between the proposed method and uniform bandit similarly to what is done in Figure 4 ?' [SEP] 'rebuttal_structuring	“Judging from Table 1, the proposed method does not seem to provide a large contribution.
Specifically, the policy update in Dreamer resembles that of SVG (Heess et al., 2015), which also backpropagates re-parameterized gradients through a value function and a transition model.' [SEP] 'rebuttal_done	We have highlighted the technical challenges we overcome in order to obtain these results in the updated version (please see Remark 3.3).
[-] It seems to me the motivation is similar to that of Sparsely-Gated MoE (Shazeer et al. 2017), but it is not clear how the proposed two-hierarchy method is superior to the Sparsely-Gated MoE. It would be helpful the paper discuss more about this.' [SEP] 'rebuttal_done	We have highlighted the technical challenges we overcome in order to obtain these results in the updated version (please see Remark 3.3).
- why do you need a conditional GAN discriminator, if you already model similarity by L1?' [SEP] 'rebuttal_structuring	The proposed method seems plausible, but some details are impressionistic and it is not clear why and whether the modeling choices do what the paper says.
A significant concern/confusion for me is that this doesn't seem to be a mixed membership model, and so I don't know how meaningful it is to generate a level distribution from a Dirichlet and then draw from that mixture one time.' [SEP] 'rebuttal_structuring	The proposed method seems plausible, but some details are impressionistic and it is not clear why and whether the modeling choices do what the paper says.
2. Is it reasonable to assume some constraints on how much data we can get from the blackbox generator?' [SEP] 'rebuttal_social	We thank R1 and R2 for endorsing the merit of our proposed black-box calibration.
"Apart from the assumption H1 of linear separability of the data (which I don't mind), the results require very strong assumptions, in particular hypothesis H2 stating ""at the beginning of training data points from different classes do not activate the same neurons"".' [SEP] 'rebuttal_social"	We thank R1 and R2 for endorsing the merit of our proposed black-box calibration.
Also pervasive is the use of the asterisk to denote multiplication, again as if it was code and not math.' [SEP] 'rebuttal_refute-question	>>> In Figure 4 of appendix A, we describe the detailed structure of the graph construction module.
Minor, 1/2 is missing in the last line of Eq 19.' [SEP] 'rebuttal_refute-question	>>> In Figure 4 of appendix A, we describe the detailed structure of the graph construction module.
It is not even clear that the final compression of the baselines would not be better.' [SEP] 'rebuttal_concede-criticism	However, we agree that this was not clear in this first revision: atoms which were displayed looked qualitatively similar.
You probably have to limit the operation to a half-sphere (there's some ideas for this in Gu et al).' [SEP] 'rebuttal_concede-criticism	However, we agree that this was not clear in this first revision: atoms which were displayed looked qualitatively similar.
Here, the straightforward regression term means directly regress the output mask to the target densepose mask. Will the proposed mask term perform better?' [SEP] 'rebuttal_answer	While we put this experiment into the appendix for now to not change the main paper too much compared to the submitted version, if the reviewers agree we would also be very happy to include this experiment in the main paper.
Apart from combining these to existing ideas, what can be considered as an added novelty to improve the quality of the disentangled features?' [SEP] 'rebuttal_answer	While we put this experiment into the appendix for now to not change the main paper too much compared to the submitted version, if the reviewers agree we would also be very happy to include this experiment in the main paper.
This was a fun, albeit incremental paper.' [SEP] 'rebuttal_structuring	[Q] The only issue with this paper is its degree of novelty, which is narrow.
However, the paper contains only little novelty and does not provide sufficiently new scientific insights.' [SEP] 'rebuttal_structuring	[Q] The only issue with this paper is its degree of novelty, which is narrow.
The originality is relative low though, since it is mainly an application of  deep InfoMax to language modeling, not inventing a new algorithm and applying to language modeling.' [SEP] 'rebuttal_answer	We provide clarification for the two main questions of the Reviewer below.
But I'm concerned with the novelty and contributions of this paper.' [SEP] 'rebuttal_answer	We provide clarification for the two main questions of the Reviewer below.
I have doubts on applying the proposed method to higher dimensional inputs.' [SEP] 'rebuttal_answer	The answers are very likely to depend on the application, data sets, etc., which we plan to study in the future.
"Here, there is only a single (unconditioned) policy, and the different ""skills"" come from modifications of the environment -- the number of skills is tied to the number of environments.' [SEP] 'rebuttal_answer"	The answers are very likely to depend on the application, data sets, etc., which we plan to study in the future.
"""Table 4 shows that our first results are promising, even though they are not as good as the state of the art."" The state of the art on LibriSpeech is not Mohamed at al. 2019. See e.g. Irie et al. Interspeech 2019 for better result' [SEP] 'rebuttal_structuring"	-Q: Actionable consequences from paper:
"The paper also lacks experimental results, and the main conclusion from these results seems to be ""MNIST is not suitable for benchmarking of adversarial attacks"".' [SEP] 'rebuttal_structuring"	-Q: Actionable consequences from paper:
2. I think that the claim that the use of neural networks with discrete inputs can approximately solve NP-hard optimization problems is an exciting one, which likely necessitates more experiments (or theoretical results), but as it stands I don't think it is a fundamentally different conclusion from the fact that this method provides a great scalable solution for the ordinal embedding problem.' [SEP] 'rebuttal_done	We have tried to revise the draft with appropriate renaming of the method to avoid potential misunderstandings.
- novelty is low: the proposed algorithm is a heuristic similar to previously proposed algorithms in the transfer learning and auxiliary learning space' [SEP] 'rebuttal_done	We have tried to revise the draft with appropriate renaming of the method to avoid potential misunderstandings.
That's a very simple kind of question; more generally, I'd like to see more analysis of the new dataset.' [SEP] 'rebuttal_answer	The reviewer raises an important point about the tested single images.
- How much does the image matter for the single-image data set?' [SEP] 'rebuttal_answer	The reviewer raises an important point about the tested single images.
2. The paper never clearly demonstrates the problem they are trying to solve (nor well differentiates it from the compressed sensing problem  or sample selection problem)' [SEP] 'rebuttal_answer	We think generating such justifications is a great next step and hope that our work will foster such interesting future research.
"-	While this is a new and interesting task, the contribution (as discussed above in “pros” above) is somewhat limited.' [SEP] 'rebuttal_answer"	We think generating such justifications is a great next step and hope that our work will foster such interesting future research.
3) In its current form, the experimental results are extremely cherry-picked, with a very small number of tasks evaluated, and for each task a single selected baseline used.' [SEP] 'rebuttal_concede-criticism	We agree that any improvements compared to RGCN are marginal.
2) The experimental results provided in this paper are weak.' [SEP] 'rebuttal_concede-criticism	We agree that any improvements compared to RGCN are marginal.
"However, as the ""selection network"" uses exactly the same input as ""classification network"", it is hard to imagine how it can learn additional information.' [SEP] 'rebuttal_structuring"	1. Comments about the contributions and novelty
The combination of ideas is ok, however, it is unclear how novel or how good is the proposed MF training of the RBMs.' [SEP] 'rebuttal_structuring	1. Comments about the contributions and novelty
A quick glance at Table 1 suggests that the bounds obtained through Theorem 3 are exponential in t and are mostly vacuous.' [SEP] 'rebuttal_structuring	Q4. The top row of Figure 2b is confusing:
"Also, Figure 6 is referenced in the text in the context of binary multiplication (""[...] is able to outperform a multiplier created just by training, as can be seen in Figure 6""), but presents results for addition and factorization only.' [SEP] 'rebuttal_structuring"	Q4. The top row of Figure 2b is confusing:
The paper motivates the problem that we need to pick out an exploration sequence that optimizes learning progress, but then approximates it as simply measuring the return.' [SEP] 'rebuttal_reject-criticism	We respectfully disagree with the reviewer's main comment that the experiments are not large scale.
- the more interesting problem, RL + auxiliary loss isn’t evaluated in detail' [SEP] 'rebuttal_reject-criticism	We respectfully disagree with the reviewer's main comment that the experiments are not large scale.
Hence the theoretical sample complexities contributed are not comparable to those of MIME.' [SEP] 'rebuttal_by-cr	For the sake of completeness, we will compare our methods with the suggested baselines in the camera ready/future versions of the paper.
Finally, the paper needs to compare its parameter-reduction approaches against other compression and hyperparameter optimization techniques.' [SEP] 'rebuttal_by-cr	For the sake of completeness, we will compare our methods with the suggested baselines in the camera ready/future versions of the paper.
In my opinion, to support the above claim, shouldn’t the authors provide a similar table as Table 1, directly comparing the certified radii of the natural images and adversarial images?' [SEP] 'rebuttal_structuring	R4: An example is presented in Figure 3 but is not expanded upon in the main text.
For example, in Table 2, the F-pooling only wins at either accuracy (marginally) or consistency, but not both.' [SEP] 'rebuttal_structuring	R4: An example is presented in Figure 3 but is not expanded upon in the main text.
Since this work takes the approach of allowing stale weight updates, the author should also compare with existing distributed training approaches that use asynchronous updates, with or without model parallelism, for example, Dean et al., 2012.' [SEP] 'rebuttal_by-cr	We plan to make our code public to aid research in the area.
- Jointly learning an inference network (Q) has certainly been done before, and I am not sure authors provide an elaborate enough explanation of what is the difference with adversarially learned inference /  adversarial feature learning.' [SEP] 'rebuttal_by-cr	We plan to make our code public to aid research in the area.
methods. There are some scalable property verification methods that can give a' [SEP] 'rebuttal_future	That said, we agree that using different architectures would strengthen our point and make the paper more convincing.
What is the benefit of using DL algorithms within the oracle-augmented datastream model?' [SEP] 'rebuttal_future	That said, we agree that using different architectures would strengthen our point and make the paper more convincing.
- The writing looks very rushed, and should be improved.' [SEP] 'rebuttal_done	We have significantly improved the writing, re-done the bibliography and citing, and organized the most important theorems and definitions into a clearer presentation.
- Missing references on page 3' [SEP] 'rebuttal_done	We have significantly improved the writing, re-done the bibliography and citing, and organized the most important theorems and definitions into a clearer presentation.
- The model G_theta does not appear in the training objective function (4), how is this module trained precisely?' [SEP] 'rebuttal_structuring	"3) - ""The experiment section lacks more detailed analysis which can intuitively explain how well the proposed method performs on the benchmarks."
methods. There are some scalable property verification methods that can give a' [SEP] 'rebuttal_structuring	"3) - ""The experiment section lacks more detailed analysis which can intuitively explain how well the proposed method performs on the benchmarks."
b) Down weighting the KL term by lambda for the VI techniques unfairly biases the comparison.' [SEP] 'rebuttal_answer	All our theory can be easily generalized to this setting using almost identical argument, which can also address your concerns on this issue.
However, based on the definition of \theta and \tilde{\theta} given in the first sentence of section 2.3, the relation between \theta, \tilde{\theta} and D' [SEP] 'rebuttal_answer	All our theory can be easily generalized to this setting using almost identical argument, which can also address your concerns on this issue.
The current tasks and problem sizes are not very convincing, and the accuracy results are not very compelling.' [SEP] 'rebuttal_social	A: Thanks for the review comment.
4. How sensitive are the results to the number of adaptive kernels in the layers.' [SEP] 'rebuttal_social	A: Thanks for the review comment.
That said, I would like to see more analysis on the behavior of the proposed method under various interesting cases not tested yet.' [SEP] 'rebuttal_answer	Given the limited space provided, it would be difficult to fit a convergence analysis in our paper.
5) Last but not least, convergence analysis of the proposed method should be provided given that asynchrony may lead to divergence in the optimization.' [SEP] 'rebuttal_answer	Given the limited space provided, it would be difficult to fit a convergence analysis in our paper.
Optimizing compression rates should be done on the training set with a separate development set.' [SEP] 'rebuttal_future	We agree that it would be interesting to perform an in-depth analysis on the embeddings learned by BERT and we will investigate this in future work.
The test set should not used before the best compression scheme is selected.' [SEP] 'rebuttal_future	We agree that it would be interesting to perform an in-depth analysis on the embeddings learned by BERT and we will investigate this in future work.
Why? If we are learning the distribution, would not it make sense to sample all architectures only after training the supernet at our best?' [SEP] 'rebuttal_by-cr	We will make all code and models trained in this paper available for reproducibility.
Cons: While doing this leads to better convergence, each update is still very expensive compared to standard SGD, and for instance on vision tasks the algorithm needs to run for almost double the time to get similar accuracies as an SGD, adam solver.' [SEP] 'rebuttal_by-cr	We will make all code and models trained in this paper available for reproducibility.
- the name 'Bundle Adjustment' is actually not adapted to the proposed method.' [SEP] 'rebuttal_future	=> We agree that significant amounts of stochasticity would break the method we used in the paper, and it is an important issue to be addressed by future work.
1). Why minimizing the upper bound in this scenario would help to minimize the loss on the target domain, when the upper bound can be substantially huge? How about just evaluate \alpha by the closeness of the source domain with the target domain?' [SEP] 'rebuttal_future	=> We agree that significant amounts of stochasticity would break the method we used in the paper, and it is an important issue to be addressed by future work.
-- Since CounMin is closely related to Bloom filters the idea of using machine learning to speed it up appears to be noticeably less novel given that for Bloom filters this has already been done by Mitzenmacher’18.' [SEP] 'rebuttal_done	It was not our intention and we will edit sections 1 and 2 to ensure that this is resolved and that the above points are reflected in the text.
- The paper does not have a significant novel contribution, but rather extends GANs (improved-GAN mostly) with a manifold regularization, which has been explored in many other works Kumar et al. (2017) and Qi et al. (2018).' [SEP] 'rebuttal_done	It was not our intention and we will edit sections 1 and 2 to ensure that this is resolved and that the above points are reflected in the text.
Many of the results have been already presented in' [SEP] 'rebuttal_reject-criticism	Although previous authors have also discussed some of these results, there are differences between our conclusions, as we discussed in our responses to the other two reviewers.
Although I personally enjoyed reading the results that from control theory perspective are inline with GAN literature, the paper does not provide novel surprising results.' [SEP] 'rebuttal_reject-criticism	Although previous authors have also discussed some of these results, there are differences between our conclusions, as we discussed in our responses to the other two reviewers.
However the theoretical contribution is poor. And the experiment uses a very classical benchmark providing simulated data.' [SEP] 'rebuttal_reject-criticism	We have added a sentence in the introduction emphasizing this crucial point.
Simply because for continuous variables similar experiments have been reported before' [SEP] 'rebuttal_reject-criticism	We have added a sentence in the introduction emphasizing this crucial point.
The experiments on synthetic data could be improved: for reproducibility, many works on GANs used the same synthetic data as VEEGAN.' [SEP] 'rebuttal_by-cr	4. We will include more related works to our paper.
However, there is no comparison with ENAS and DARTS in experiments.' [SEP] 'rebuttal_by-cr	4. We will include more related works to our paper.
-- Since CounMin is closely related to Bloom filters the idea of using machine learning to speed it up appears to be noticeably less novel given that for Bloom filters this has already been done by Mitzenmacher’18.' [SEP] 'rebuttal_structuring	"In response to your comment that ""similar ideas have been undertaken (e.g., Mescheder et al 2018), but in different contexts"" we would like to take this opportunity to clarify the novelty of our approach."
1) The introduction makes it seem the generative replay is new, without citing approaches such as DGR (which are cited in the related work).' [SEP] 'rebuttal_structuring	"In response to your comment that ""similar ideas have been undertaken (e.g., Mescheder et al 2018), but in different contexts"" we would like to take this opportunity to clarify the novelty of our approach."
have no idea how confident the sampling based result is.' [SEP] 'rebuttal_future	For these reasons (and more provided below), we thus think it more fair (and necessary) to make such experiments the subject of a future paper.
"The column ""FLOPS"" in the result seems to measure the speedup, whereas the actual FLOPS should be less when the speed increases.' [SEP] 'rebuttal_future"	For these reasons (and more provided below), we thus think it more fair (and necessary) to make such experiments the subject of a future paper.
The imagenet experiment lacks details.' [SEP] 'rebuttal_by-cr	5. We will add more details about the experiments to the appendix.
In summary, I think this is interesting work, but a clearer explanation of the relationship between HRL and MARL, as well as a clearer main argument, supported by experimental evidence, would greatly improve this paper.' [SEP] 'rebuttal_by-cr	5. We will add more details about the experiments to the appendix.
While the use of a GAN in general will make the results less blurry and visually appealing, it does not necessarily mean that the samples it generates are going to be plausible or better.' [SEP] 'rebuttal_by-cr	- Table 3 is indeed confusing, this is a good point. We will correct it.
"The column ""FLOPS"" in the result seems to measure the speedup, whereas the actual FLOPS should be less when the speed increases.' [SEP] 'rebuttal_by-cr"	- Table 3 is indeed confusing, this is a good point. We will correct it.
Tiny detail: The axes of several of the plots given in the paper mis the lables which makes it hard to read. Straightforward to fix, but worth mentioning nevertheless.' [SEP] 'rebuttal_done	Thanks for this; we have updated the draft to make the presentation clearer.
The input and output types of each block in Figure 1. should be clearly stated.' [SEP] 'rebuttal_done	Thanks for this; we have updated the draft to make the presentation clearer.
"I believe that's what ""Pred (One Step)"" expresses, but it would maybe be generally helpful to be more precise about the notation' [SEP] 'rebuttal_social"	We thank the reviewer for the questions on optimization ability, generalization error, etc. These are interesting research directions.
In addition, the subindex ‘1’ of the point ‘q’ is not explained.' [SEP] 'rebuttal_social	We thank the reviewer for the questions on optimization ability, generalization error, etc. These are interesting research directions.
This needs to be changed: a) you should run all the baselines for each of the current tasks b) you should also expand the experiments evaluated to include tasks where it is not obvious that a hierarchy would help/is necessary c) you should include more baselines.' [SEP] 'rebuttal_reject-criticism	While we are fastidious in our experimental description in Section 3, we think it is necessary since this is the foundational section of the paper.
I would imagine that even if an embedding X is a bit noisy, because not exactly equal to gamma(P) where P is the expression it represents, you could consider doing the propagation with gamma(G(X)).' [SEP] 'rebuttal_reject-criticism	While we are fastidious in our experimental description in Section 3, we think it is necessary since this is the foundational section of the paper.
3. The graph neural networks used in the model are not described in the paper, only a reference to Paliwal et al (2019) is given.' [SEP] 'rebuttal_answer	As explained in the response to Reviewer 1, despite all our efforts, we found the technical challenges insurmountable given our computational and engineering resources.
It would be helpful to have a brief paragraph describing this architecture, for readers not familiar with the referenced paper.' [SEP] 'rebuttal_answer	As explained in the response to Reviewer 1, despite all our efforts, we found the technical challenges insurmountable given our computational and engineering resources.
- The shown inception scores are far from state-of-the-art.' [SEP] 'rebuttal_answer	Also, in the revised document, we have expanded the caption of Table 1 to make sure that it is clear what a certified is and that a larger radii is better.
But the paper only provides empirical results on sentimental analysis and digit recognition.' [SEP] 'rebuttal_answer	Also, in the revised document, we have expanded the caption of Table 1 to make sure that it is clear what a certified is and that a larger radii is better.
Hence, I am not very sure whether the novelty of the paper is significant.' [SEP] 'rebuttal_reject-criticism	However, our work differs in two major ways:
This was a fun, albeit incremental paper.' [SEP] 'rebuttal_reject-criticism	However, our work differs in two major ways:
- Lack of sufficient technical detail on models and dataset' [SEP] 'rebuttal_answer	We purposely traded breadth for depth in our investigations, and we will go even deeper in the additional experiments that the upcoming revision will contain.
4. How large is the training set of (T, P) pairs? I don't think this is mentioned in the paper.' [SEP] 'rebuttal_answer	We purposely traded breadth for depth in our investigations, and we will go even deeper in the additional experiments that the upcoming revision will contain.
In my opinion, due to how many researchers are and have been looking into improvements of language modeling, the authors may find it hard to break new ground in this direction.' [SEP] 'rebuttal_answer	We also didn't choose particular hyperparameters to ensure diversity for our models, and we expect some improvement in diversity in the new sets of experiments.
While the presentation is clear and the evaluation of the model is thorough, I am unsure of the significance of the proposed method.' [SEP] 'rebuttal_answer	We also didn't choose particular hyperparameters to ensure diversity for our models, and we expect some improvement in diversity in the new sets of experiments.
Therefore, I don’t find interesting to report how DDGC improve upon “no baseline”, because known methods do even better.' [SEP] 'rebuttal_done	We also included the suggested related work (Balduzzi et al. 2018) in Section 5.
"- In the appendix, the statement ""Sarkar (2011) show that a similar statement as in Theorem 2 holds for a very general class of trees"" is confusing to me. The ""general class"", as far as I know, is actually *all* trees, weighted or unweighted.' [SEP] 'rebuttal_done"	We also included the suggested related work (Balduzzi et al. 2018) in Section 5.
Because, the results are only shown on one dataset, it is harder to see how one might extend this work to other form of questions on slightly harder datasets.' [SEP] 'rebuttal_reject-criticism	Actually, we have evaluated the proposed methods by conducting experiments in many datasets and observed the similar results.
It is necessary to test it on datasets with much more fine classes and much-complicated hierarchy, e.g., ImageNet, MS COCO or their subsets, which have ideal class hierarchy structures.' [SEP] 'rebuttal_reject-criticism	Actually, we have evaluated the proposed methods by conducting experiments in many datasets and observed the similar results.
In some RL tasks, it is not allowed to access the RAM state.' [SEP] 'rebuttal_summary	This supplementary material contains code to replicate all figures but also additional experiments to test the effect of the different parameters.
"When you say that full-matrix computation ""requires taking the inverse square root"", I assume you know that is not really correct?' [SEP] 'rebuttal_summary"	This supplementary material contains code to replicate all figures but also additional experiments to test the effect of the different parameters.
Although I really appreciate the authors' efforts on providing implementational details in the appendix, the code and data do not seem to be publicly available, and I'm expecting that the implementation of this technique is relatively hard due to their complex designs of the generator and discriminator.' [SEP] 'rebuttal_reject-request	Due to the space restriction, however, we cannot present them all in the paper.
While reviewing this paper I went back and read the EN-DE evaluation data for the last few years trying to see how often I could reason that images would help and I came up severely lacking.' [SEP] 'rebuttal_reject-request	Due to the space restriction, however, we cannot present them all in the paper.
- it is not really clear to be what data the graphs show: the boxplots show 5% of what data? does it also include the models obtained by gaussian process regression? and what about the line plots, is it the best model so far as you train more and more models? if so, how are those models chosen and ordered? are they the results of single models or average of multiple ones?' [SEP] 'rebuttal_concede-criticism	We apologize for unclear description of experimental settings.
"* The descriptor distributions in Figure 3 don't look like an ""almost exact match"" to me (as claimed in the text).' [SEP] 'rebuttal_concede-criticism"	We apologize for unclear description of experimental settings.
* The biggest problem for me was the unconvincing results.' [SEP] 'rebuttal_concede-criticism	We acknowledge that Section 3, which is a preliminary analysis, may confuse the reader in the first place.
I would suggest the authors to either introduce the two problems earlier or to simply say that near-optimal results are achieved, without giving detailed results, because it is very hard to understand them without any introduction of the task being achieved.' [SEP] 'rebuttal_concede-criticism	We acknowledge that Section 3, which is a preliminary analysis, may confuse the reader in the first place.
Given the title of the paper, it would have been nice if this paper explored more than just MNIST vs NotMNIST and SVHN vs CIFAR10, so that the readers can gain a better feel for when generative models will be able to detect outliers.' [SEP] 'rebuttal_mitigate-criticism	We have opted, in this submission, to focus on our primary application domain, which is intuitive physics.
The second order analysis is good but it seems to come down to just a measure of the empirical variances of the datasets.' [SEP] 'rebuttal_mitigate-criticism	We have opted, in this submission, to focus on our primary application domain, which is intuitive physics.
The results of the paper do not give major insights into what are the preferred techniques for training GANs, and certainly not why and under what circumstances they'll work.' [SEP] 'rebuttal_done	We will update the labels in the ablation table to make this more clear.
The results  are overall not very impressive.' [SEP] 'rebuttal_done	We will update the labels in the ablation table to make this more clear.
However, this only affects the method of drawing the samples from a fixed known distribution and should have no more effect on the results than say a choice of a pseudo-random number generator.' [SEP] 'rebuttal_structuring	So, two responses are given below.
2. As to the results of the Pose2Pose network, I wonder if there are some artifacts that will affect the performance of the Pose2Frame network.' [SEP] 'rebuttal_structuring	So, two responses are given below.
Another somewhat jarring fact about the alt-az convolution is that it is not well defined on the south pole.' [SEP] 'rebuttal_structuring	"""Some technical details are missing."
-Something is a bit weird with the FGM results. While it is a weaker attack, a 0%/100% disparity between it and every other' [SEP] 'rebuttal_structuring	"""Some technical details are missing."
The biased introduced via this truncation has been studied in great depth in [3] and shown to be harmful.' [SEP] 'rebuttal_by-cr	Nonetheless, we will cite it and discuss its approach in comparison to ours in the related work section of the final revised version of our paper.
I believe it will not be great, but I think for completeness, you should add such a baseline.' [SEP] 'rebuttal_by-cr	Nonetheless, we will cite it and discuss its approach in comparison to ours in the related work section of the final revised version of our paper.
1). Why minimizing the upper bound in this scenario would help to minimize the loss on the target domain, when the upper bound can be substantially huge? How about just evaluate \alpha by the closeness of the source domain with the target domain?' [SEP] 'rebuttal_social	[A3] We were very impressed with the mathematical detail of the reviewer’s comment and thanked you to the reviewer again. If the reviewer agrees with our argument, we will reflect the argument in our paper.
However, it does exclude some popular activation families, such as the polynomial activation, which were proven effective in multiple areas.' [SEP] 'rebuttal_social	[A3] We were very impressed with the mathematical detail of the reviewer’s comment and thanked you to the reviewer again. If the reviewer agrees with our argument, we will reflect the argument in our paper.
I believe it will not be great, but I think for completeness, you should add such a baseline.' [SEP] 'rebuttal_structuring	Q4. Updated abstract and performance evaluation.
Better literature review to reflect the relevant previous video action recognitions, especially those on video compositional models.' [SEP] 'rebuttal_structuring	Q4. Updated abstract and performance evaluation.
The paper shows two applications (semi-supervised learning and novelty detection) and it is not clear that the proposed method outperforms existing GAN methods in the classification accuracy in MNIST/SVHN/CIFAR10 (Table 1) and existing sampling methods (Table. 3).' [SEP] 'rebuttal_mitigate-criticism	We also compared to other methods demonstrating the better scalability of our approach, cf. Table 2.
It seems that the discriminator takes a whole sequence as input, but some precision on how this done could be added.' [SEP] 'rebuttal_mitigate-criticism	We also compared to other methods demonstrating the better scalability of our approach, cf. Table 2.
As is, the counter example proof itself is quite confusing: it would really help if the proof was more formal.' [SEP] 'rebuttal_summary	In terms of GR, we are trying to address the two open questions mentioned above.
For example, it is unclear to me why some larger models are not amenable to truncation.' [SEP] 'rebuttal_summary	In terms of GR, we are trying to address the two open questions mentioned above.
In terms of applicability, it seems that many cases where discrete latent variables would be really interesting are not covered (e.g. sigmoid belief networks); the paper demonstrates experiments with discrete images (binary or 4-bit) not particularly motivated in my opinion.' [SEP] 'rebuttal_answer	"Even if they did show these convincingly, it is not obvious to me that it is valuable."", we have performed the same experiments on more iterations such that we clearly see that baseline stay separate."
Specifically, the author mentioned Tsai et al. assumed factorized latent variables from the multimodal data, while Tsai et al. actually assumed the generation of multimodal data consists of disentangled modality-specific and multimodal factors.' [SEP] 'rebuttal_answer	"Even if they did show these convincingly, it is not obvious to me that it is valuable."", we have performed the same experiments on more iterations such that we clearly see that baseline stay separate."
The paper also misses relevant citations of similar questions from the field of (probabilistic) matrix factorization and relational learning.' [SEP] 'rebuttal_summary	Actually we was going to cite this paper yet considering the significant difference we finally did not cite it in the original version.
This is a thriving area that requires a careful literature review.' [SEP] 'rebuttal_summary	Actually we was going to cite this paper yet considering the significant difference we finally did not cite it in the original version.
It is also not clear to me how domain translation is relevant to continual learning.' [SEP] 'rebuttal_future	We leave it as a future work to study where the clear boundary is.
My biggest concern in the methodology, however, has to do with the selection of the matrix variate normal prior for the weights and the imposition of diagonal covariances (diag(a) and diag(b)).' [SEP] 'rebuttal_future	We leave it as a future work to study where the clear boundary is.
It is fine, but it seems weird that the author still mentioned the setup of MNIST+SVHN in the main text.' [SEP] 'rebuttal_concede-criticism	Thanks, these help improve the presentation greatly (we realize we wrote the exposition more  from a theoretical view and missed important ML details).
"Some statements don't make sense, however, eg. ""HSIC-based estimators tend to have loose confidence intervals due to the need to bound generalization error of kernels f and g on unseen data points.' [SEP] 'rebuttal_concede-criticism"	Thanks, these help improve the presentation greatly (we realize we wrote the exposition more  from a theoretical view and missed important ML details).
3. This apart, I think that the experiment section is pretty hard to read, given all the metrics and methodology is in the Appendix.' [SEP] 'rebuttal_answer	We added new experiments showing the agent can learn to manipulate two balls.
The experimental section includes various mistakes (see under minor) and misses to describe figures, leading to the assumption that additional time is required for a more detailed evaluation of the algorithm (including more domains and in particular baselines).' [SEP] 'rebuttal_answer	We added new experiments showing the agent can learn to manipulate two balls.
There were some experimental details that were poorly explained but in general the paper was readable.' [SEP] 'rebuttal_concede-criticism	A : We apologize to the reviewer for the lack of clarity in the manuscript. We have modified our expression.
- Also, for MISC-r experiments, the weights between the intrinsic reward bonus and the extrinsic reward are not specified in the paper.' [SEP] 'rebuttal_concede-criticism	A : We apologize to the reviewer for the lack of clarity in the manuscript. We have modified our expression.
The current experimental settings are not matched with the practice environment.' [SEP] 'rebuttal_concede-criticism	2) For the experiment, we will train our experiments longer and modify our network.
this is important since all your experiments rely on that assumption.' [SEP] 'rebuttal_concede-criticism	2) For the experiment, we will train our experiments longer and modify our network.
little improvements over the baselines or even significantly worse. More importantly,' [SEP] 'rebuttal_concede-criticism	Nevertheless, we agree with your comments that it is more meaningful to emphasize our improvement over the state-of-the-art training methods.
* first paragraph page 2: some references to causality literature and definition of spuriousness as common cause' [SEP] 'rebuttal_concede-criticism	Nevertheless, we agree with your comments that it is more meaningful to emphasize our improvement over the state-of-the-art training methods.
While, the paper is a plaisant read, I find difficult to access its importance and the applicability of the ideas presented beyond the analogy with the capacity computation. Perhaps other referee will have a clearer opinion.' [SEP] 'rebuttal_done	In the new revision, we have added a discussion section to make a case for this.
(2) The method is not well motivated.' [SEP] 'rebuttal_done	In the new revision, we have added a discussion section to make a case for this.
If so it would be better to define the operator in a more general notation.' [SEP] 'rebuttal_social	We will gladly provide files with the trained weights and also fully trained neural networks on request.
Section 3 too much redundancy -- it just explains that SVHN has a higher likelihood when trained on CIFAR, and a few variations of the same experiment.' [SEP] 'rebuttal_social	We will gladly provide files with the trained weights and also fully trained neural networks on request.
1) The motivation is unclear and overall structure of the paper is confusing.' [SEP] 'rebuttal_done	We attempted to much  improve the clarity of our paper by adding further explanations and correcting typos in many places.
The writing is understandable for the most part, but the paper seems to lack focus - there is no clear take home message.' [SEP] 'rebuttal_done	We attempted to much  improve the clarity of our paper by adding further explanations and correcting typos in many places.
The advantage of this random encoding was to reduce the number of parameters for an embedding layer, but the results showed we gained much PPL from a 25% reduction in embedding size (Table 1).' [SEP] 'rebuttal_reject-request	Unfortunately, we cannot release the dataset, since we do not own the videos, but we will share our code.
4. How sensitive are the results to the number of adaptive kernels in the layers.' [SEP] 'rebuttal_reject-request	Unfortunately, we cannot release the dataset, since we do not own the videos, but we will share our code.
However, as presented these ideas are poorly justified and careful comparisons against sensible baselines are missing.' [SEP] 'rebuttal_social	Thank you for pointing out paper [3].
- The WGAN-GP baseline is very weak, i.e. does not show any reasonable generated images (Fig. 9).' [SEP] 'rebuttal_social	Thank you for pointing out paper [3].
"Section 2.1 is where the method is proposed, yet most of the descriptions there are unclear. Without these details it is impossible to judge the novelty of the ""rule-based concept extractor"", which is the key technical innovation.' [SEP] 'rebuttal_reject-request"	Though this is an interesting direction, it is outside the scope of the work we present here, which concerns itself with the learned representations themselves.
It would be better if the authors were a little more careful in their use of terminology here.' [SEP] 'rebuttal_reject-request	Though this is an interesting direction, it is outside the scope of the work we present here, which concerns itself with the learned representations themselves.
4. Mean field analysis, although it lends an insight into the statistics of the activations, needs to connected with empirical observations.' [SEP] 'rebuttal_concede-criticism	As a follow-up, for existing datasets, our next steps include investigating how to make these adjustments in a cost-effective way.
Moreover, said the analysis is in my opinion not sufficiently rigorous, with hand-wavy arguments, no formal proof and unclear terms (e.g. how do you define near-optimal?)' [SEP] 'rebuttal_concede-criticism	As a follow-up, for existing datasets, our next steps include investigating how to make these adjustments in a cost-effective way.
First of all, the setup for the AE and VAE is not specified.' [SEP] 'rebuttal_concede-criticism	Thanks for pointing out that our original introduction to the names of baselines and models is not very clear.
How does the proposed method perform in more complicated tasks such as' [SEP] 'rebuttal_concede-criticism	Thanks for pointing out that our original introduction to the names of baselines and models is not very clear.
- It isn't clear from the tables that OCE_0.1 outperforms REINFORCE_Z (as is mentioned in the discussion).' [SEP] 'rebuttal_structuring	> Weakness: the presentation of the tables/bar charts in the experiment is a bit unclear.
Furthermore, the usage of the evaluation method unclear as well, it seems to be designed for evaluating the effectiveness of different adversarial attacks in Figure 2.' [SEP] 'rebuttal_structuring	> Weakness: the presentation of the tables/bar charts in the experiment is a bit unclear.
1) Provide stronger empirical results (these are not too convincing).' [SEP] 'rebuttal_done	We also added Figure 6 which better highlights the properties of the algorithms and we performed several additional studies, described either in the main text or in appendices.
* The biggest problem for me was the unconvincing results.' [SEP] 'rebuttal_done	We also added Figure 6 which better highlights the properties of the algorithms and we performed several additional studies, described either in the main text or in appendices.
Since this work takes the approach of allowing stale weight updates, the author should also compare with existing distributed training approaches that use asynchronous updates, with or without model parallelism, for example, Dean et al., 2012.' [SEP] 'rebuttal_reject-criticism	While we disagree, we did however undertake a significant effort to further clarify and provide additional evidence in the revised manuscript, taking into account these comments.
There is no experiment clearly shows convincing evidence of the correctness of the proposed approach or its utility compared to existing approaches (Xie & Ermon (2019); Kool et al. (2019); PlÂšotz & Roth (2018) ).' [SEP] 'rebuttal_reject-criticism	While we disagree, we did however undertake a significant effort to further clarify and provide additional evidence in the revised manuscript, taking into account these comments.
First, In Theorem 2, which seems to be a main result of the paper, the authors were concerned with the condition when W_{ji} >0, but there is not conclusion if W_{ji} =0.' [SEP] 'rebuttal_done	To show that we can easily include these features, we have included in our appendix some results including non-structural features.
Even with the hybrid method, the accuracy still drops.' [SEP] 'rebuttal_done	To show that we can easily include these features, we have included in our appendix some results including non-structural features.
- novelty: the additions proposed are small modifications to existing algorithms and there are other methods of attention on graphs which have been discussed in the paper but not directly compared to (e.g. this method builds heavily on Velickovic et al 2017)' [SEP] 'rebuttal_done	In addition to the locations specified by the reviewer, the first two paragraphs of Section 1 (especially the second paragraph) discuss several other related works.
While the section 4 has a discussion on related papers, there's no systematic experimental comparison across these methods.' [SEP] 'rebuttal_done	In addition to the locations specified by the reviewer, the first two paragraphs of Section 1 (especially the second paragraph) discuss several other related works.
"For example, I don't understand what does it mean in ""However, if training data is complete, ..... handle during missing data during test."" Another example would be the last few paragraphs on page 4; they are very unclear.' [SEP] 'rebuttal_answer"	Please see the last paragraph in page 5.
"For example, I have trouble understanding the sentence ""So the existed algorithms should be heuristic or it can get a bad result even we train the neural networks with lots of datasets."" in the introduction.' [SEP] 'rebuttal_answer"	Please see the last paragraph in page 5.
Ultimately this paper is interesting but falls well below the standards of exposition that I expect from a theory paper and doesn’t go very far at connecting the analysis back to the claimed motivation of investigating practical invariances. If the authors significantly improve the quality of the draft, I’ll be happy to revisit it and re-evaluate my score.' [SEP] 'rebuttal_reject-criticism	We respectfully disagree with the reviewer’s suggestion that a fundamentally distinct resource warrants only a whitepaper.
It reads very much like a STOC theory paper, and a lot of the key ML details that would be relevant to audience at this conference seem to have been shoved under the rug in a way.' [SEP] 'rebuttal_reject-criticism	We respectfully disagree with the reviewer’s suggestion that a fundamentally distinct resource warrants only a whitepaper.
The way the permutation, or the order of the data, accounts in the likelihood (2) does not make sense.' [SEP] 'rebuttal_done	Fig. 3 and other evaluations have been updated for the new test set.
Considering the small size of the corpus for the evaluation of a regularization method, the results even seem optimistic - it remains unclear, if this approach would readily scale to larger datasets.' [SEP] 'rebuttal_done	Fig. 3 and other evaluations have been updated for the new test set.
All in all, the results show that the proposed method provides a significant speedup with respect to Shim et al., but it lacks comparison with other methods in the literature.' [SEP] 'rebuttal_answer	Upon your suggestion, we would also add this random baseline in table 2 as well.
In addition, only the transformer baselines were considered, and it would seem natural to consider LSTM-based baselines, or some other related techniques.' [SEP] 'rebuttal_answer	Upon your suggestion, we would also add this random baseline in table 2 as well.
There were some experimental details that were poorly explained but in general the paper was readable.' [SEP] 'rebuttal_done	(6) We updated the appendix to address this. See “Training convergence” in Appendix D.2
This needs more elaboration. Is this way of training results expected? What is the lesson learned?' [SEP] 'rebuttal_done	(6) We updated the appendix to address this. See “Training convergence” in Appendix D.2
2. The authors should provide ablation study and analysis of their CTAugment.' [SEP] 'rebuttal_reject-criticism	Please see the 2nd paragraph of Sec. 4.1 and Lemma 7.15.
Moreover, said the analysis is in my opinion not sufficiently rigorous, with hand-wavy arguments, no formal proof and unclear terms (e.g. how do you define near-optimal?)' [SEP] 'rebuttal_reject-criticism	Please see the 2nd paragraph of Sec. 4.1 and Lemma 7.15.
The presented analysis seems to neglect the error term corresponding to the value function.' [SEP] 'rebuttal_answer	We focus on the noiseless case here to convey the main idea, since the analysis is already very involved.
- The analysis in [1] handles the case of noisy updates, whereas the analysis given here only works for exact updates.' [SEP] 'rebuttal_answer	We focus on the noiseless case here to convey the main idea, since the analysis is already very involved.
We think that this is not enough, and more extensive experimental results would provide a better paper.' [SEP] 'rebuttal_answer	These additional expositions further showcase the contributions of our work both on theoretical and practical online DL front.
The paper does not talk about settings where states of interest are not known, so all of the experiments are based on this strong assumption.' [SEP] 'rebuttal_answer	These additional expositions further showcase the contributions of our work both on theoretical and practical online DL front.
It is also not clear to me why these problems are important.' [SEP] 'rebuttal_structuring	Re. somewhat limited contribution:
The idea is an interesting one, but' [SEP] 'rebuttal_structuring	Re. somewhat limited contribution:
- I might have missed that, but are the authors offering an interpretation of their observation that the performance of the self-modulation model performs worse in the combination of spectral normalization and the SNDC architecture?' [SEP] 'rebuttal_reject-request	Finally on the same point, we have not used at this point any application, such as supervised learning,  as it is out of the scope of this paper. But we thank the reviewer for suggesting it.
Another concern is that the evaluation of domain adaptation does not have much varieties.' [SEP] 'rebuttal_reject-request	Finally on the same point, we have not used at this point any application, such as supervised learning,  as it is out of the scope of this paper. But we thank the reviewer for suggesting it.
However, the method they propose offers very little that is new when compared to e.g. Vaswani (https://arxiv.org/pdf/1706.03762.pdf, section 3.5) (the authors acknowledge this work several times).' [SEP] 'rebuttal_structuring	"Concerning the point "" It is not even clear that the final compression of the baselines would not be better."
6. Similar as above question, on the object counting task, is there a way to compare with previous counting methods?' [SEP] 'rebuttal_structuring	"Concerning the point "" It is not even clear that the final compression of the baselines would not be better."
- It is extremely hard to follow what exactly is going on; I believe a few illustrative examples would help make the paper much clearer; in fact the idea is not that abstract.' [SEP] 'rebuttal_structuring	Q2. It is extremely hard to follow what exactly is going on; I believe a few illustrative examples would help make the paper much clearer; in fact the idea is not that abstract.
- The problem setting description is neither formal nor intuitive which made it very hard for me to understand exactly the problem you are trying to solve.' [SEP] 'rebuttal_structuring	Q2. It is extremely hard to follow what exactly is going on; I believe a few illustrative examples would help make the paper much clearer; in fact the idea is not that abstract.
- it is not really clear to be what data the graphs show: the boxplots show 5% of what data? does it also include the models obtained by gaussian process regression? and what about the line plots, is it the best model so far as you train more and more models? if so, how are those models chosen and ordered? are they the results of single models or average of multiple ones?' [SEP] 'rebuttal_summary	Additional evidence that there is no overfitting is the good extrapolation results (section 7), as acknowledged by the reviewer.
The second order analysis is good but it seems to come down to just a measure of the empirical variances of the datasets.' [SEP] 'rebuttal_summary	Additional evidence that there is no overfitting is the good extrapolation results (section 7), as acknowledged by the reviewer.
"- There are better words than ""decent"" to describe the performance of DARTS, as it's very similar to the results in this work!' [SEP] 'rebuttal_answer"	We’ve also revised Appendix A.1 to cover details of how PPO is incorporated.
This paper presents non-trivial theoretical results that are worth to be published but as I argue below its has a weak relevance to practice and the applicability of the obtained results is unclear.' [SEP] 'rebuttal_answer	We’ve also revised Appendix A.1 to cover details of how PPO is incorporated.
Although I personally enjoyed reading the results that from control theory perspective are inline with GAN literature, the paper does not provide novel surprising results.' [SEP] 'rebuttal_structuring	> “The results are not strong. And, unfortunately, the model contribution currently is too modest.”
However, this limits the novelty of the results relative to existing literature.' [SEP] 'rebuttal_structuring	> “The results are not strong. And, unfortunately, the model contribution currently is too modest.”
- the higher-order features T*a*b are useful only when a is noun and b is an adjective: why not investigate using T to model higher-order interaction for all (a,b) pairs regardless of the syntactic relationships between a and b?' [SEP] 'rebuttal_reject-criticism	Therefore, to demonstrate the power of our approach further, we have also performed evaluation on the synthetic datasets.
Since the novelty of this work lies in the introduction of the CW distance, I would like to see an independent evaluation of this distance as a  general statistical distance measure (independently of its use in CWAE).' [SEP] 'rebuttal_reject-criticism	Therefore, to demonstrate the power of our approach further, we have also performed evaluation on the synthetic datasets.
#9) I think that MNIST is almost a toy experiment, since the crucial component of the proposed method is the prior modeling with the GAN.' [SEP] 'rebuttal_reject-criticism	However, we feel this maybe a bit harsh, as in the technical content of the paper (Abstract, Introduction, etc.), we have been very clear about the motivation and the problem setting, and do not think we did any form of false advertising.
However, unlike as advertised, the paper does not address the domain shift issue in meta-learning, and the experiments lack thorough evaluation as the paper considers itself as a meta-learning paper and only compares to other meta-learning approaches without much comparison to domain adaptation papers.' [SEP] 'rebuttal_reject-criticism	However, we feel this maybe a bit harsh, as in the technical content of the paper (Abstract, Introduction, etc.), we have been very clear about the motivation and the problem setting, and do not think we did any form of false advertising.
- The analysis in [1] handles the case of noisy updates, whereas the analysis given here only works for exact updates.' [SEP] 'rebuttal_done	Concerning including more comparison and ablations in the paper, we have performed an extended analysis of our method to the baselines across many environments.
"2.	What is the reason for using rule-based agents in all the experiments? It would have been more useful if all the analysis are done with RL agents rather than rule-based agents.' [SEP] 'rebuttal_done"	Concerning including more comparison and ablations in the paper, we have performed an extended analysis of our method to the baselines across many environments.
Only some heuristic results are obtained for them without rigorous theory.' [SEP] 'rebuttal_answer	Again, we think the exact inference accuracy of the model is somewhat orthogonal to our study.
Indeed, the manuscript introduces sample complexity results to justify the benefits of the out-of-sample procedure (th 1), but it seems to me that these give an incomplete picture.' [SEP] 'rebuttal_answer	Again, we think the exact inference accuracy of the model is somewhat orthogonal to our study.
The paper used very restricted Gaussian distributions for the formulation.' [SEP] 'rebuttal_summary	Thus, we suggested applying the domain translation to address this issue.
Finally, it is unclear how the authors have picked the best \lambda parameter for their approach? On page 5 they state that they “pick the value that results in a good trade-off between high uncertainty estimates and high prediction accuracy.” Does this mean that you get to observe the performance in the test in order to select the appropriate value for \lambda? If this is the case this is completely undesirable and is considered a bad practice.' [SEP] 'rebuttal_summary	Thus, we suggested applying the domain translation to address this issue.
It is a minor weak point that the algorithm can work only when the abstract state is obtained by the RAM state.' [SEP] 'rebuttal_reject-criticism	The selling point isn't the generality of the result, but rather the novelty of the approach and the potential it suggests for future work that would be more general.
- In Theorem 4.7 an expectation on g(x_a) is missing' [SEP] 'rebuttal_reject-criticism	The selling point isn't the generality of the result, but rather the novelty of the approach and the potential it suggests for future work that would be more general.
"The proposed method adapt a previously presented hierarchical clustering method in the ""standard space"" (Griffiths et al., 2004) to an embedding space defined by a variational autoencoder model.' [SEP] 'rebuttal_structuring"	> I am reluctant to give a higher score due to its incremental contribution.
The proposed approach is very similar to the CE method by Rubinstein (as stated by the authors in the related work section), limiting the contributions of this paper.' [SEP] 'rebuttal_structuring	> I am reluctant to give a higher score due to its incremental contribution.
It is not clear how the compression ratio in table 1 is obtained.' [SEP] 'rebuttal_answer	Please also refer to the main contribution (ii) of our response to Reviewer 2.
2. Even though Figure 2b shows that SVHN test likelihoods are higher than CIFAR test likelihoods, the overlap in the histograms of CIFAR-train and CIFAR-test is much higher than the overlap in CIFAR-train and SVHN-test.' [SEP] 'rebuttal_answer	Please also refer to the main contribution (ii) of our response to Reviewer 2.
- Did the experiments on CIFAR-10 and ImageNet use the cosine learning rate schedule [1]? If or if not, either way, you should specify it in a revised version of this paper, e.g. did you use the cosine schedule in the first 120 steps to train the shared parameters W, did you use it in the retraining from scratch?' [SEP] 'rebuttal_done	We have already uploaded our source codes as well as the demonstration videos to the following sites.
- Although the authors discussed the experiment setting in detail in supplements, I believe open-sourcing the code / software used to conduct the experiments would be greatly help with the reproducibility of the proposed method for researchers or practitioners.' [SEP] 'rebuttal_done	We have already uploaded our source codes as well as the demonstration videos to the following sites.
- The paper does not have a significant novel contribution, but rather extends GANs (improved-GAN mostly) with a manifold regularization, which has been explored in many other works Kumar et al. (2017) and Qi et al. (2018).' [SEP] 'rebuttal_mitigate-criticism	Nevertheless, although the experimental increases might not seem dramatic, they are statistically significant (we have added the statistical significance results to the appendix in the revised version).
"Taking a random example (there are others by simple searching), in the ECCV paper ""DFT-based Transformation Invariant Pooling Layer for Visual Classification, Ryu et al., 2018"" The DFT magnitude pooling is almost the same as the authors' propositions, where the ""Fourier coefficients are cropped by cutting off high-frequency components"".' [SEP] 'rebuttal_mitigate-criticism"	Nevertheless, although the experimental increases might not seem dramatic, they are statistically significant (we have added the statistical significance results to the appendix in the revised version).
* the idea of smoothing gradients is not new' [SEP] 'rebuttal_structuring	1. We first want to point out the main contributions of the paper.
I do not see much insight into the problem.' [SEP] 'rebuttal_structuring	1. We first want to point out the main contributions of the paper.
It is also not clear to me why CIFAR datasets involve two domains and how these domains are relevant in each of the tasks.' [SEP] 'rebuttal_done	We believe that, together with other architectural details present in the paper, it makes our work reproducible.
While reviewing this paper I went back and read the EN-DE evaluation data for the last few years trying to see how often I could reason that images would help and I came up severely lacking.' [SEP] 'rebuttal_done	We believe that, together with other architectural details present in the paper, it makes our work reproducible.
The convergence analysis is on Z, not on parameters x and hyper-parameters theta.' [SEP] 'rebuttal_structuring	So, bounds here cannot be used to explain empirical observations in Section 5.
This has not been considered in the analysis.' [SEP] 'rebuttal_structuring	So, bounds here cannot be used to explain empirical observations in Section 5.
However, only 1 dataset pair is experimented -- there should be more to ensure the findings generalize, since Sections 3 and 4 rely completely on empirical analysis.' [SEP] 'rebuttal_reject-criticism	We already have more material than fits in this paper, especially now that we have added clarifications that all reviewers requested.
Regarding contrastive explanations, experiments on datasets where distractor classes (y_probe) are present in addition to the class interest (y_true) seem important -- PASCAL VOC, COCO, etc.' [SEP] 'rebuttal_reject-criticism	We already have more material than fits in this paper, especially now that we have added clarifications that all reviewers requested.
2) The experimental results provided in this paper are weak.' [SEP] 'rebuttal_done	Response: The replicates correspond to different training and validation samples of the enriched set -- we have clarified this in the paper.
(1) The experimental results cannot show the usefulness of the proposed GCN.' [SEP] 'rebuttal_done	Response: The replicates correspond to different training and validation samples of the enriched set -- we have clarified this in the paper.
The paper is well-written but the structure is a bit disconnected; most notably, I didn't see clearly how Section 2 and 3 fit together.' [SEP] 'rebuttal_concede-criticism	In addition, there are indeed a few places in the paper where our phrasing could have been better, thank you for pointing this out.
The overall presentation could be better, and I would encourage the authors to tidy the paper up in any subsequent submission.' [SEP] 'rebuttal_concede-criticism	In addition, there are indeed a few places in the paper where our phrasing could have been better, thank you for pointing this out.
- Yuri Burda, Roger Grosse, Ruslan Salakhutdinov. Importance Weighted Autoencoders. ICLR 2016' [SEP] 'rebuttal_done	* In relation to the connection to IWAE, we have included a detailed discussion in Appendix E.1.
See http://www.stat.cmu.edu/~ryantibs/convexopt-S15/scribes/08-prox-grad-scribed.pdf for a reference.' [SEP] 'rebuttal_done	* In relation to the connection to IWAE, we have included a detailed discussion in Appendix E.1.
In some RL tasks, it is not allowed to access the RAM state.' [SEP] 'rebuttal_by-cr	Response: Thanks for the constructive suggestion. We agree with the reviewer and will make this assumption explicit in the revised manuscript.
My concern here is that beta might be affecting the result more than the proposed training algorithm.' [SEP] 'rebuttal_by-cr	Response: Thanks for the constructive suggestion. We agree with the reviewer and will make this assumption explicit in the revised manuscript.
- In active learning, the proposed method should be compared with other methods such as Bayesian DNN using dropout, etc.' [SEP] 'rebuttal_social	We hope that you will agree that, with your kind feedback, the changes above strengthen the paper's claims and clarity, and that you are willing to reconsider your assessment on these grounds.
As I have mentioned above, actually a lot of methods have been developed to address general image restoration tasks.' [SEP] 'rebuttal_social	We hope that you will agree that, with your kind feedback, the changes above strengthen the paper's claims and clarity, and that you are willing to reconsider your assessment on these grounds.
Although some promising' [SEP] 'rebuttal_answer	We discuss the novelty aspects in our general response ( https://openreview.net/forum?id=HkMlGnC9KQ&noteId=S1eid00WaQ ) and will be happy to clarify this in the paper.
- The experiments seem very similar to Wu et al. 2018, which is considered to be prior work under the ICLR guidelines.' [SEP] 'rebuttal_answer	We discuss the novelty aspects in our general response ( https://openreview.net/forum?id=HkMlGnC9KQ&noteId=S1eid00WaQ ) and will be happy to clarify this in the paper.
Moreover, I don't think some of the presented experiments are necessary.' [SEP] 'rebuttal_summary	Please also see the comparison in the last paragraph of Section 3, which we will extend with the present discussion.
The experiments of this paper lack comparisons to certified verification' [SEP] 'rebuttal_summary	Please also see the comparison in the last paragraph of Section 3, which we will extend with the present discussion.
- It would be nice if more network architectures were analysed (such as VGG and DenseNets).' [SEP] 'rebuttal_structuring	[The analysis is relatively straightforward]
"-2 Diversity of additional ""agents"" not analyzed (more below).' [SEP] 'rebuttal_structuring"	[The analysis is relatively straightforward]
The results are not strong. And, unfortunately, the model contribution currently is too modest.' [SEP] 'rebuttal_mitigate-criticism	As we explained at the common response, we started our research from clear open questions.
Many of the results have been already presented in' [SEP] 'rebuttal_mitigate-criticism	As we explained at the common response, we started our research from clear open questions.
The KL divergence regularization introduces extra randomness to the auxiliary labels and thus mitigates the problem, but it hardly provides any useful information except randomness.' [SEP] 'rebuttal_done	Therefore, we have modified our expression and added the result in Section 6.4 of the supplementary material.
It’s also unclear if the proposed method is more memory efficient, since the authors only unroll 4 iterations of it.' [SEP] 'rebuttal_done	Therefore, we have modified our expression and added the result in Section 6.4 of the supplementary material.
Unlike Arora's original work, the assumptions they make on their subject material are not supported enough, as in their lack of explanation of why linear addition of two word embeddings should be a bad idea for composition of the embedding vectors of two syntactically related words, and why the corrective term produced by their method makes this a good idea.' [SEP] 'rebuttal_future	This is an interesting avenue for research and we hope that this paper could inspire follow-up work on this topic.
-- The overall error model in this paper, which is borrowed from Roy et al. is quite restrictive as at it assumes that the queries to the frequency estimation data structure are coming from the same distribution as that given by f_i’s themselves.' [SEP] 'rebuttal_future	This is an interesting avenue for research and we hope that this paper could inspire follow-up work on this topic.
"The title claims way more than what is actually delivered in the paper, despite the fact that the authors have put in an ""On"" in the beginning of the title.' [SEP] 'rebuttal_done"	results in the updated paper.
* Also in the introduction, it is implied that style transfer constitutes an advance in generative models, but style transfer does not make use of / does not equate to any generative model.' [SEP] 'rebuttal_done	results in the updated paper.
Hence it is unclear how large the running time improvement is compared to a well-tuned baseline.' [SEP] 'rebuttal_concede-criticism	In the original manuscript, we had to limit the detailed information of the previous work due to the page limit.
"In the last paragraph in Related Work, ""provide"" should be ""provides"".' [SEP] 'rebuttal_concede-criticism"	In the original manuscript, we had to limit the detailed information of the previous work due to the page limit.
So at the end, I am a bit puzzled. I really like the idea, but I have the feeling that this technique should have been developed for more complicated setting. Or maybe it is actually not working on more difficult combinatorial problem (and this is hidden in the paper).' [SEP] 'rebuttal_concede-criticism	We apologize if we painted an incorrect picture by calling it a “simple example” and a “staple introductory problem”.
It would be nice to position the ideas from the paper w.r.t. this line of research too.' [SEP] 'rebuttal_concede-criticism	We apologize if we painted an incorrect picture by calling it a “simple example” and a “staple introductory problem”.
- for Figure 6, there is not a clear conclusion.' [SEP] 'rebuttal_summary	There exist three parameters in this experiment, which makes it hard to come up with the most conclusive representation.
- in section 4.3 how is the reconstruction built (Figure 3b)?' [SEP] 'rebuttal_summary	There exist three parameters in this experiment, which makes it hard to come up with the most conclusive representation.
- Is there actionable consequences one could draw from your papers? The way the results are presented seem like they are only useful inspection after training; are your results able to derive methods to enforce conditions on the pre-images for example?' [SEP] 'rebuttal_done	We have modified our text to avoid possible misunderstandings (see end of next-to-last paragraph in Section 4).
The authors claim that some amount of noise can be tolerated, but do not quantify how much.' [SEP] 'rebuttal_done	We have modified our text to avoid possible misunderstandings (see end of next-to-last paragraph in Section 4).
"And the analysis of the ""dynamic range"" of the algorithim is missing.' [SEP] 'rebuttal_future"	We leave more comprehensive studies on diversity to future work.
While this assumption seems plausible,  no analysis has been done to verify it in a systematic way.' [SEP] 'rebuttal_future	We leave more comprehensive studies on diversity to future work.
The paper has few really minor grammatical errors and typos. Please fix those before uploading the final draft.' [SEP] 'rebuttal_structuring	We would like to start by clarifying the difference between the final implementation (what the reviewer referred to as engineering contribution) of our method with its scientific contribution.
5. The paper is imprecise and unpolished and the presentation needs improvement.' [SEP] 'rebuttal_structuring	We would like to start by clarifying the difference between the final implementation (what the reviewer referred to as engineering contribution) of our method with its scientific contribution.
The results  are overall not very impressive.' [SEP] 'rebuttal_reject-criticism	[A]  We respectfully disagree.
This is not so interesting, even though results are impressive.' [SEP] 'rebuttal_reject-criticism	[A]  We respectfully disagree.
Therefore,  the faster convergence demonstrated in the experiments can not be explained by Theorem 3.1 or Theorem 3.2.' [SEP] 'rebuttal_refute-question	Though not explained in Section 4.
2. Though seemingly very important to the architecture, the purpose of constructing the super-graph g^{sup} in the training of C^{CAT} seems to be unclear to me.' [SEP] 'rebuttal_refute-question	Though not explained in Section 4.
- why do you need a conditional GAN discriminator, if you already model similarity by L1?' [SEP] 'rebuttal_mitigate-criticism	For this particular work, our focus is to introduce the high-level ideas/framework and offer initial evidence that it can be effective, so we do not dwell much on the technical parts of ML in our discussion due to page limits.
I consider this assumption unrealistic.' [SEP] 'rebuttal_mitigate-criticism	For this particular work, our focus is to introduce the high-level ideas/framework and offer initial evidence that it can be effective, so we do not dwell much on the technical parts of ML in our discussion due to page limits.
